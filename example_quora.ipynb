{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "I0302 18:21:31.321669 140447729411904 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0302 18:21:31.967522 140447729411904 file_utils.py:57] TensorFlow version 2.0.0 available.\n",
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning:\n",
      "\n",
      "The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from catalyst import dl\n",
    "import wandb\n",
    "import joblib\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "# your working dir\n",
    "mydir = '/data2/competitions/quora-insincere-questions-classification'\n",
    "SEED = 1234\n",
    "\n",
    "tqdm.pandas()\n",
    "# seed everything\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_size(model, trainable=True):\n",
    "    if trainable:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "    else:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    return psize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-apply-exponential-moving-average-decay-for-variables/10856\n",
    "class EMA():\n",
    "    def __init__(self, model, mu, level='batch', n=1):\n",
    "        \"\"\"\n",
    "        level: 'batch' or 'epoch'\n",
    "          'batch': Update params every n batches.\n",
    "          'epoch': Update params every epoch.\n",
    "        \"\"\"\n",
    "        # self.ema_model = copy.deepcopy(model)\n",
    "        self.mu = mu\n",
    "        self.level = level\n",
    "        self.n = n\n",
    "        self.cnt = self.n\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data\n",
    "\n",
    "    def _update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1 - self.mu) * param.data + self.mu * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def set_weights(self, ema_model):\n",
    "        for name, param in ema_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def on_batch_end(self, model):\n",
    "        if self.level is 'batch':\n",
    "            self.cnt -= 1\n",
    "            if self.cnt == 0:\n",
    "                self._update(model)\n",
    "                self.cnt = self.n\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.level is 'epoch':\n",
    "            self._update(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, h_size, n_layers, dropout, padding_idx, \n",
    "                 pretrained_embedding=None, fix_embedding=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.is_pretrained = pretrained_embedding is not None\n",
    "        \n",
    "        if self.is_pretrained:\n",
    "            self.embed = nn.Embedding.from_pretrained(pretrained_embedding, freeze=fix_embedding)\n",
    "            self.embed.padding_idx = padding_idx\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "            \n",
    "        # dropout after embeddings\n",
    "        self.embed_drop = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embed_dim, h_size, n_layers, \n",
    "                          batch_first=True, \n",
    "                          bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        # use Sequential for FFNN\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*n_layers*h_size, h_size),\n",
    "            nn.BatchNorm1d(h_size),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(h_size, 1),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        if not self.is_pretrained:\n",
    "            d = self.embed.weight.size(1)\n",
    "            nn.init.uniform_(self.embed.weight, -1/np.sqrt(d), 1/np.sqrt(d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.embed_drop(x)\n",
    "        x, _ = self.gru(x)\n",
    "        x, _ = torch.max(x, 1)\n",
    "        x = self.out(x).squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "     \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "     def __init__(self, examples, fields, filter_pred=None):\n",
    "         \"\"\"\n",
    "         Create a dataset from a pandas dataframe of examples and Fields\n",
    "         Arguments:\n",
    "             examples pd.DataFrame: DataFrame of examples\n",
    "             fields {str: Field}: The Fields to use in this tuple. The\n",
    "                 string is a field name, and the Field is the associated field.\n",
    "             filter_pred (callable or None): use only exanples for which\n",
    "                 filter_pred(example) is true, or use all examples if None.\n",
    "                 Default is None\n",
    "         \"\"\"\n",
    "         self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "         if filter_pred is not None:\n",
    "             self.examples = filter(filter_pred, self.examples)\n",
    "         self.fields = dict(fields)\n",
    "         # Unpack field tuples\n",
    "         for n, f in list(self.fields.items()):\n",
    "             if isinstance(n, tuple):\n",
    "                 self.fields.update(zip(n, f))\n",
    "                 del self.fields[n]\n",
    "                    \n",
    "class SeriesExample(data.Example):\n",
    "     \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "     @classmethod\n",
    "     def fromSeries(cls, data, fields):\n",
    "         return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "     @classmethod\n",
    "     def fromdict(cls, data, fields):\n",
    "         ex = cls()\n",
    "\n",
    "         for key, field in fields.items():\n",
    "             if key not in data:\n",
    "                 raise ValueError(\"Specified key {} was not found in \"\n",
    "                 \"the input data\".format(key))\n",
    "             if field is not None:\n",
    "                 setattr(ex, key, field.preprocess(data[key]))\n",
    "             else:\n",
    "                 setattr(ex, key, data[key])\n",
    "         return ex\n",
    "\n",
    "# Simple wrapper to join torchtext and catalyst API\n",
    "\n",
    "class IteratorWrapper(torch.utils.data.DataLoader):\n",
    "    __initialized__ = False\n",
    "\n",
    "    def __init__(self, iter: iter):\n",
    "        self.batch_size = iter.batch_size\n",
    "        self.num_workers = 1\n",
    "        self.collate_fn = None\n",
    "        self.pin_memory = False\n",
    "        self.drop_last = False\n",
    "        self.timeout = 0\n",
    "        self.worker_init_fn = None\n",
    "        self.sampler = iter\n",
    "        self.batch_sampler = iter\n",
    "        self.__initialized__ = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(lambda batch: {\n",
    "                    'features': batch.text,\n",
    "                    'targets': batch.target,\n",
    "                }, self.batch_sampler.__iter__())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "puncts = ',.\":)(-!?|;\\'$&/[]>%=#*+\\\\•~@£·_{}©^®`<→°€™›♥←×§″′Â█½à…“★”–●â►−¢²¬░¶↑±¿▾═¦║\\\n",
    "―¥▓—‹─▒：¼⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸¾Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡√'\n",
    "\n",
    "\n",
    "def clean_text(x, puncts=puncts): #добавляет пробелы вокруг пунктуации\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b14647e0b534c0e847682faa85716c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa444c9722dc4ee2a56aa25193380c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2887444daa2c47eabeaaca1d4fc45d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{mydir}/train.csv', index_col=0)\n",
    "df_train = df_train.rename(columns={'question_text': 'text'})\n",
    "\n",
    "df_train['text'] = df_train['text'].progress_apply(str.lower)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_text)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_numbers)\n",
    "\n",
    "df_train, df_test = train_test_split(df_train, train_size=0.7, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822856, 91429)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 50\n",
    "\n",
    "TEXT = data.Field(\n",
    "#     include_lengths=True,\n",
    "                  postprocessing = lambda batch, vocab: [x[:max_len] for x in batch],\n",
    "                  lower=True,\n",
    "                  tokenize='spacy', \n",
    "                  tokenizer_language='en', \n",
    "                  batch_first=True\n",
    "                 )\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train = DataFrameDataset(df_train, fields={'text': TEXT, 'target': LABEL})\n",
    "test = DataFrameDataset(df_test, fields={'text': TEXT, 'target': LABEL})\n",
    "\n",
    "TEXT.build_vocab(train, test, min_freq=5)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "train, valid = train.split(split_ratio=0.9)\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_size = 128\n",
    "num_epochs = 10 \n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "embed_dim = 128\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n",
    "                                                               batch_size=batch_size, \n",
    "                                                               sort_key=lambda x: len(x.text),\n",
    "                                                               sort=True,\n",
    "                                                               device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = IteratorWrapper(train_iter)\n",
    "valid_iter = IteratorWrapper(valid_iter)\n",
    "test_iter = IteratorWrapper(test_iter)\n",
    "loaders = {'train': train_iter, 'valid': valid_iter}\n",
    "\n",
    "\n",
    "model = GRUModel(vocab_size=vocab_size, \n",
    "                 embed_dim=embed_dim, \n",
    "                 h_size=h_size, \n",
    "                 n_layers=n_layers, \n",
    "                 dropout=dropout, \n",
    "                 padding_idx=TEXT.vocab.stoi['<pad>'], \n",
    "                 pretrained_embedding=None, \n",
    "                 fix_embedding=False)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=2, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = f'{mydir}/log_quora2'\n",
    "!rm -rf {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/denaas/text-augmentation\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/denaas/text-augmentation/runs/iv0xcy91\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation/runs/iv0xcy91</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:38:28.034538 140447729411904 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:38:28.035439 140447729411904 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:38:28.312668 140447729411904 run_manager.py:951] resuming run from id: UnVuOnYxOml2MHhjeTkxOnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:38:28.332295 140447729411904 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:38:28.607837 140442043508480 run_manager.py:1048] saving patches\n",
      "I0302 18:38:28.671578 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/config.yaml\n",
      "I0302 18:38:29.026587 140442043508480 run_manager.py:1052] saving pip packages\n",
      "I0302 18:38:29.028063 140442043508480 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:38:29.028974 140442043508480 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:38:29.356307 140442075133696 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-summary.json\n",
      "I0302 18:38:29.357369 140442075133696 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n",
      "I0302 18:38:29.358170 140442075133696 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-history.jsonl\n",
      "I0302 18:38:29.359246 140442075133696 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-events.jsonl\n",
      "I0302 18:38:29.670803 140442075133696 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/diff.patch\n",
      "I0302 18:38:29.671992 140442075133696 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  92% 1481/1608 [00:16<00:01, 84.23it/s, loss=0.219] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:38:46.850527 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 1608/1608 [00:17<00:00, 89.64it/s, loss=0.578]\n",
      "1/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 161.39it/s, loss=0.251]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:38:49.866588 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-history.jsonl\n",
      "I0302 18:38:49.867388 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-summary.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:38:50,003] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118858.6015 | _timers/batch_time=0.0065 | _timers/data_time=0.0054 | _timers/model_time=0.0011 | loss=0.1298\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=114324.3365 | _timers/batch_time=0.0051 | _timers/data_time=0.0041 | _timers/model_time=0.0010 | loss=0.1558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:38:50.003142 140447729411904 logging.py:153] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118858.6015 | _timers/batch_time=0.0065 | _timers/data_time=0.0054 | _timers/model_time=0.0011 | loss=0.1298\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=114324.3365 | _timers/batch_time=0.0051 | _timers/data_time=0.0041 | _timers/model_time=0.0010 | loss=0.1558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  69% 1106/1608 [00:09<00:04, 110.66it/s, loss=0.089]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:38:59.879318 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  81% 1307/1608 [00:11<00:03, 98.57it/s, loss=0.146] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:01.881912 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train): 100% 1608/1608 [00:15<00:00, 102.25it/s, loss=0.245]\n",
      "2/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 170.50it/s, loss=0.277]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:06.891876 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-history.jsonl\n",
      "I0302 18:39:06.892608 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-summary.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:39:07,643] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=117076.5020 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0961\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120055.0663 | _timers/batch_time=0.0049 | _timers/data_time=0.0039 | _timers/model_time=0.0010 | loss=0.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:07.643361 140447729411904 logging.py:153] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=117076.5020 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0961\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120055.0663 | _timers/batch_time=0.0049 | _timers/data_time=0.0039 | _timers/model_time=0.0010 | loss=0.1750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  73% 1166/1608 [00:10<00:04, 100.44it/s, loss=0.100]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:17.985757 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train): 100% 1608/1608 [00:15<00:00, 103.85it/s, loss=0.085]\n",
      "3/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 178.23it/s, loss=0.359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:24.997493 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-history.jsonl\n",
      "I0302 18:39:24.999510 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-summary.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at 2 epoch\n",
      "[2020-03-02 18:39:25,011] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119700.9695 | _timers/batch_time=0.0050 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0745\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=124843.4703 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0010 | loss=0.2056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:25.011820 140447729411904 logging.py:153] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119700.9695 | _timers/batch_time=0.0050 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0745\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=124843.4703 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0010 | loss=0.2056\n",
      "I0302 18:39:25.016955 140447729411904 run_manager.py:1068] shutting down system stats and metadata service\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top best models:\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora2/checkpoints/train.1.pth\t0.1558\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora2/checkpoints/train.2.pth\t0.1750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:25.927115 140447729411904 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:39:25.998388 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n",
      "I0302 18:39:26.000784 140447729411904 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-events.jsonl\n",
      "I0302 18:39:26.002572 140447729411904 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/valid_log/events.out.tfevents.1583163528.UNIT-1482.9902.1\n",
      "I0302 18:39:26.003966 140447729411904 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/log.txt\n",
      "I0302 18:39:26.005576 140447729411904 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/train_log/events.out.tfevents.1583163510.UNIT-1482.9902.0\n",
      "I0302 18:39:26.007193 140447729411904 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/train_log\n",
      "I0302 18:39:26.008761 140447729411904 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/valid_log\n",
      "I0302 18:39:26.009989 140447729411904 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_153827-iv0xcy91/checkpoints\n"
     ]
    }
   ],
   "source": [
    "# use SupervisedWandbRunner runner to send statistics to wandb\n",
    "runner = dl.SupervisedWandbRunner(DEVICE)\n",
    "runner.train(model, \n",
    "             loaders=loaders,\n",
    "             num_epochs=num_epochs,\n",
    "             logdir=logdir,\n",
    "             criterion=nn.BCEWithLogitsLoss(),\n",
    "             optimizer=optimizer, \n",
    "             scheduler=scheduler,  \n",
    "             callbacks=[\n",
    "                dl.callbacks.CheckpointCallback(2), # save 2 best models (by epoch) into logdir\n",
    "                dl.callbacks.EarlyStoppingCallback(3), # stop training, if valid loss does not improve last 3 epochs\n",
    "             ],\n",
    "             # send current hyperparam values to wandb\n",
    "             monitoring_params={\n",
    "                 'entity': 'denaas', # your wandb username\n",
    "                 'project': 'text-augmentation', # project name\n",
    "                 'name': 'quora-noembed-original', # name of the specific run\n",
    "                 'group': 'examples',\n",
    "                 'config': {\n",
    "                     'model': 'bigru',\n",
    "                     'optimizer': str(optimizer),\n",
    "                     'scheduler': 'plateau',\n",
    "                     'early_stop': 3,\n",
    "                     'vocab_size': vocab_size,\n",
    "                     'h_size': h_size,\n",
    "                     'n_layers': n_layers,\n",
    "                     'dropout': dropout,\n",
    "                     'batch_size': batch_size,\n",
    "                     'embed_dim': embed_dim,\n",
    "                     'max_len': max_len,\n",
    "                 },\n",
    "             },\n",
    "#              check=True, # set if you want to check pipeline for correctness, without actual training\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl.utils.unpack_checkpoint(dl.utils.load_checkpoint(f'{logdir}/checkpoints/best_full.pth'), model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6141959868823301 0.6382812500000004 0.9489274833350626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:39:38.873837 140447729411904 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:39:38.877126 140447729411904 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "I0302 18:39:39.151937 140447729411904 run_manager.py:951] resuming run from id: UnVuOnYxOml2MHhjeTkxOnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:39:39.173845 140447729411904 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "I0302 18:39:39.442445 140442060293888 run_manager.py:1048] saving patches\n",
      "I0302 18:39:39.501732 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n",
      "I0302 18:39:39.930966 140442060293888 run_manager.py:1052] saving pip packages\n",
      "I0302 18:39:39.932473 140442060293888 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:39:39.933523 140442060293888 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "I0302 18:39:39.934738 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-history.jsonl\n",
      "I0302 18:39:39.935380 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-summary.json\n",
      "I0302 18:39:39.936353 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-events.jsonl\n",
      "I0302 18:39:39.936937 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/config.yaml\n",
      "I0302 18:39:39.949492 140447729411904 run_manager.py:1068] shutting down system stats and metadata service\n",
      "I0302 18:39:40.503631 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-history.jsonl\n",
      "I0302 18:39:40.505894 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-summary.json\n",
      "I0302 18:39:40.509309 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/diff.patch\n",
      "I0302 18:39:40.511831 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-events.jsonl\n",
      "I0302 18:39:40.512708 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/requirements.txt\n",
      "I0302 18:39:40.876163 140447729411904 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:39:41.507542 140442075133696 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_153827-iv0xcy91/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "# find threshold on valid dataset\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, valid_iter)\n",
    "# convert logits to probabilities\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in valid_iter])\n",
    "res = scipy.optimize.minimize(\n",
    "    lambda t: -metrics.f1_score(y_true, (y_proba >= t).astype(np.int)),\n",
    "    x0=0.5,\n",
    "    method='Nelder-Mead',\n",
    "    tol=1e-3,\n",
    ")\n",
    "threshold = res.x[0]\n",
    "\n",
    "\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, test_iter)\n",
    "# convert logits to probabilities\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in test_iter])\n",
    "\n",
    "auc_test = metrics.roc_auc_score(y_true, y_proba)\n",
    "f1_test = metrics.f1_score(y_true, (y_proba >= threshold).astype(np.int))\n",
    "\n",
    "print(f1_test, threshold, auc_test)\n",
    "wandb.log({'scores/f1': f1_test, 'scores/f1_threshold': threshold, 'scores/f1_auc': auc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
