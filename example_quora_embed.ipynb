{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "I0302 18:09:55.359832 139869237638976 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0302 18:09:55.992824 139869237638976 file_utils.py:57] TensorFlow version 2.0.0 available.\n",
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning:\n",
      "\n",
      "The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from catalyst import dl\n",
    "import wandb\n",
    "import joblib\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "mydir = '/data2/competitions/quora-insincere-questions-classification'\n",
    "SEED = 1234\n",
    "\n",
    "tqdm.pandas()\n",
    "# seed everything\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_size(model, trainable=True):\n",
    "    if trainable:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "    else:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    return psize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-apply-exponential-moving-average-decay-for-variables/10856\n",
    "class EMA():\n",
    "    def __init__(self, model, mu, level='batch', n=1):\n",
    "        \"\"\"\n",
    "        level: 'batch' or 'epoch'\n",
    "          'batch': Update params every n batches.\n",
    "          'epoch': Update params every epoch.\n",
    "        \"\"\"\n",
    "        # self.ema_model = copy.deepcopy(model)\n",
    "        self.mu = mu\n",
    "        self.level = level\n",
    "        self.n = n\n",
    "        self.cnt = self.n\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data\n",
    "\n",
    "    def _update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1 - self.mu) * param.data + self.mu * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def set_weights(self, ema_model):\n",
    "        for name, param in ema_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def on_batch_end(self, model):\n",
    "        if self.level is 'batch':\n",
    "            self.cnt -= 1\n",
    "            if self.cnt == 0:\n",
    "                self._update(model)\n",
    "                self.cnt = self.n\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.level is 'epoch':\n",
    "            self._update(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "def load_glove(word_index):\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    embeddings_index = dict(get_coefs(*o.split(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    unknown_words = []\n",
    "    \n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(word_index), embed_size))\n",
    "        \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "            if embedding_vector is None:\n",
    "                unknown_words.append((word, i))\n",
    "            else:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('\\nTotal unknowns glove', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "def load_wiki(word_index):\n",
    "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    embeddings_index = dict(get_coefs(*o.split(' ')) for o in open(EMBEDDING_FILE) if len(o) > 100)\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    unknown_words = []\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(word_index), embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "            if embedding_vector is None:\n",
    "                unknown_words.append((word, i))\n",
    "            else:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('\\nTotal unknowns wiki', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "def load_parag(word_index):\n",
    "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    embeddings_index = dict(get_coefs(*o.split(' '))\n",
    "                            for o in open(EMBEDDING_FILE, encoding='utf8', errors='ignore')\n",
    "                            if len(o) > 100)\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    unknown_words = []\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(word_index), embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "            if embedding_vector is None:\n",
    "                unknown_words.append((word, i))\n",
    "            else:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('\\nTotal unknowns parag', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "def load_ggle(word_index):\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "    embeddings_index = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "    embed_size = embeddings_index.get_vector('known').size\n",
    "\n",
    "    unknown_words = []\n",
    "    embedding_matrix = (np.random.rand(len(word_index), embed_size) - 0.5) / 5.0\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index.get_vector(word)\n",
    "        else:\n",
    "            word_lower = word.lower()\n",
    "            if word_lower in embeddings_index:\n",
    "                embedding_matrix[i] = embeddings_index.get_vector(word_lower)\n",
    "            else:\n",
    "                unknown_words.append((word, i))\n",
    "\n",
    "    print('\\nTotal unknowns ggle', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, h_size, n_layers, dropout, padding_idx, \n",
    "                 pretrained_embedding=None, fix_embedding=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.is_pretrained = pretrained_embedding is not None\n",
    "        \n",
    "        if self.is_pretrained:\n",
    "            self.embed = nn.Embedding.from_pretrained(pretrained_embedding, freeze=fix_embedding)\n",
    "            self.embed.padding_idx = padding_idx\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "        \n",
    "        self.embed_drop = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embed_dim, h_size, n_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*n_layers*h_size, h_size),\n",
    "            nn.BatchNorm1d(h_size),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(h_size, 1),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        if not self.is_pretrained:\n",
    "            d = self.embed.weight.size(1)\n",
    "            nn.init.uniform_(self.embed.weight, -1/np.sqrt(d), 1/np.sqrt(d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.embed_drop(x)\n",
    "        x, _ = self.gru(x)\n",
    "        x, _ = torch.max(x, 1)\n",
    "        x = self.out(x).squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "     \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "     def __init__(self, examples, fields, filter_pred=None):\n",
    "         \"\"\"\n",
    "         Create a dataset from a pandas dataframe of examples and Fields\n",
    "         Arguments:\n",
    "             examples pd.DataFrame: DataFrame of examples\n",
    "             fields {str: Field}: The Fields to use in this tuple. The\n",
    "                 string is a field name, and the Field is the associated field.\n",
    "             filter_pred (callable or None): use only exanples for which\n",
    "                 filter_pred(example) is true, or use all examples if None.\n",
    "                 Default is None\n",
    "         \"\"\"\n",
    "         self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "         if filter_pred is not None:\n",
    "             self.examples = filter(filter_pred, self.examples)\n",
    "         self.fields = dict(fields)\n",
    "         # Unpack field tuples\n",
    "         for n, f in list(self.fields.items()):\n",
    "             if isinstance(n, tuple):\n",
    "                 self.fields.update(zip(n, f))\n",
    "                 del self.fields[n]\n",
    "                    \n",
    "class SeriesExample(data.Example):\n",
    "     \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "     @classmethod\n",
    "     def fromSeries(cls, data, fields):\n",
    "         return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "     @classmethod\n",
    "     def fromdict(cls, data, fields):\n",
    "         ex = cls()\n",
    "\n",
    "         for key, field in fields.items():\n",
    "             if key not in data:\n",
    "                 raise ValueError(\"Specified key {} was not found in \"\n",
    "                 \"the input data\".format(key))\n",
    "             if field is not None:\n",
    "                 setattr(ex, key, field.preprocess(data[key]))\n",
    "             else:\n",
    "                 setattr(ex, key, data[key])\n",
    "         return ex\n",
    "\n",
    "# Simple wrapper to join torchtext and catalyst API\n",
    "\n",
    "class IteratorWrapper(torch.utils.data.DataLoader):\n",
    "    __initialized__ = False\n",
    "\n",
    "    def __init__(self, iter: iter):\n",
    "        self.batch_size = iter.batch_size\n",
    "        self.num_workers = 1\n",
    "        self.collate_fn = None\n",
    "        self.pin_memory = False\n",
    "        self.drop_last = False\n",
    "        self.timeout = 0\n",
    "        self.worker_init_fn = None\n",
    "        self.sampler = iter\n",
    "        self.batch_sampler = iter\n",
    "        self.__initialized__ = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(lambda batch: {\n",
    "                    'features': batch.text,\n",
    "                    'targets': batch.target,\n",
    "                }, self.batch_sampler.__iter__())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "puncts = ',.\":)(-!?|;\\'$&/[]>%=#*+\\\\•~@£·_{}©^®`<→°€™›♥←×§″′Â█½à…“★”–●â►−¢²¬░¶↑±¿▾═¦║\\\n",
    "―¥▓—‹─▒：¼⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸¾Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡√'\n",
    "\n",
    "\n",
    "def clean_text(x, puncts=puncts): #добавляет пробелы вокруг пунктуации\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b68db876ed84271945f64a4b343bdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef050a66219474d9348cc684c45685d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd3e1b8dbc3467aa51a045aee59cd82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{mydir}/train.csv', index_col=0)\n",
    "df_train = df_train.rename(columns={'question_text': 'text'})\n",
    "\n",
    "df_train['text'] = df_train['text'].progress_apply(str.lower)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_text)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_numbers)\n",
    "\n",
    "df_train, df_test = train_test_split(df_train, train_size=0.7, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(822856, 91429)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 50\n",
    "\n",
    "TEXT = data.Field(\n",
    "                  postprocessing = lambda batch, vocab: [x[:max_len] for x in batch],\n",
    "                  lower=True,\n",
    "                  tokenize='spacy', \n",
    "                  tokenizer_language='en', \n",
    "                  batch_first=True)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train = DataFrameDataset(df_train, fields={'text': TEXT, 'target': LABEL})\n",
    "test = DataFrameDataset(df_test, fields={'text': TEXT, 'target': LABEL})\n",
    "\n",
    "TEXT.build_vocab(train, test, min_freq=1)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "train, valid = train.split(split_ratio=0.9)\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185888"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = dict(TEXT.vocab.stoi)\n",
    "# embedding_matrix_1, _ = load_glove(word_index)\n",
    "# embedding_matrix_2, _ = load_wiki(word_index)\n",
    "# embedding_matrix_3, _ = load_parag(word_index)\n",
    "# embedding_matrix_4, _ = load_ggle(word_index)\n",
    "\n",
    "# embedding_matrix = np.hstack((embedding_matrix_1, \n",
    "#                               embedding_matrix_2,\n",
    "#                               embedding_matrix_3,\n",
    "#                               embedding_matrix_4))\n",
    "# del embedding_matrix_1, embedding_matrix_2, embedding_matrix_3, embedding_matrix_4\n",
    "\n",
    "# joblib.dump(embedding_matrix, f'{mydir}/embedding_matrix')\n",
    "\n",
    "embedding_matrix = joblib.load(f'{mydir}/embedding_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_size = 128\n",
    "num_epochs = 10 \n",
    "n_layers = 1\n",
    "dropout = 0.2\n",
    "embed_dim = embedding_matrix.shape[1]\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n",
    "                                                               batch_size=batch_size, \n",
    "                                                               sort_key=lambda x: len(x.text),\n",
    "                                                               sort=True,\n",
    "                                                               device=DEVICE)\n",
    "train_iter = IteratorWrapper(train_iter)\n",
    "valid_iter = IteratorWrapper(valid_iter)\n",
    "test_iter = IteratorWrapper(test_iter)\n",
    "loaders = {'train': train_iter, 'valid': valid_iter}\n",
    "\n",
    "\n",
    "model = GRUModel(vocab_size=vocab_size, \n",
    "                 embed_dim=embed_dim, \n",
    "                 h_size=h_size, \n",
    "                 n_layers=n_layers, \n",
    "                 dropout=dropout, \n",
    "                 padding_idx=TEXT.vocab.stoi['<pad>'], \n",
    "                 pretrained_embedding=torch.tensor(embedding_matrix).float(), \n",
    "                 fix_embedding=True)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=2, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = f'{mydir}/log_quora1'\n",
    "!rm -rf {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/denaas/text-augmentation\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/denaas/text-augmentation/runs/0ap4z17m\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation/runs/0ap4z17m</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:12:37.242854 139869237638976 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:12:37.244071 139869237638976 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:12:37.543257 139869237638976 run_manager.py:951] resuming run from id: UnVuOnYxOjBhcDR6MTdtOnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:12:37.565651 139869237638976 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "I0302 18:12:37.842063 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/config.yaml\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:12:37.877508 139861820270336 run_manager.py:1048] saving patches\n",
      "I0302 18:12:38.440521 139861820270336 run_manager.py:1052] saving pip packages\n",
      "I0302 18:12:38.442026 139861820270336 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:12:38.443096 139861820270336 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:12:38.727312 139861851895552 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:12:38.728666 139861851895552 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:12:38.729877 139861851895552 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:12:38.730968 139861851895552 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:12:38.839279 139861851895552 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/diff.patch\n",
      "I0302 18:12:38.840470 139861851895552 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  89% 1424/1608 [00:15<00:02, 84.98it/s, loss=0.138] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:12:55.610726 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 1608/1608 [00:18<00:00, 87.68it/s, loss=0.672]\n",
      "1/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 162.19it/s, loss=0.329]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:13:00.663387 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:13:00.664492 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:13:02,986] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=116159.7151 | _timers/batch_time=0.0068 | _timers/data_time=0.0056 | _timers/model_time=0.0012 | loss=0.1197\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=128642.3233 | _timers/batch_time=0.0046 | _timers/data_time=0.0036 | _timers/model_time=0.0010 | loss=0.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:13:02.986194 139869237638976 logging.py:153] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=116159.7151 | _timers/batch_time=0.0068 | _timers/data_time=0.0056 | _timers/model_time=0.0012 | loss=0.1197\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=128642.3233 | _timers/batch_time=0.0046 | _timers/data_time=0.0036 | _timers/model_time=0.0010 | loss=0.1221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  55% 887/1608 [00:07<00:05, 121.62it/s, loss=0.072]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:13:10.133784 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  69% 1115/1608 [00:09<00:04, 111.05it/s, loss=0.115]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:13:12.134839 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train): 100% 1608/1608 [00:15<00:00, 104.90it/s, loss=0.240]\n",
      "2/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 160.08it/s, loss=0.287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:13:20.170768 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:13:20.171578 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:13:29.177090 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:13:41.186951 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:13:45.189335 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:14:00.294060 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:14:12.307579 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:14:16.310575 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:14:19,388] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120482.3016 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.1002\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=125724.3892 | _timers/batch_time=0.0046 | _timers/data_time=0.0036 | _timers/model_time=0.0010 | loss=0.1175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:14:19.388062 139869237638976 logging.py:153] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120482.3016 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.1002\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=125724.3892 | _timers/batch_time=0.0046 | _timers/data_time=0.0036 | _timers/model_time=0.0010 | loss=0.1175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  91% 1461/1608 [00:13<00:01, 75.04it/s, loss=0.131] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:14:33.323537 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train): 100% 1608/1608 [00:16<00:00, 96.90it/s, loss=0.121]\n",
      "3/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 148.96it/s, loss=0.292]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:14:37.954852 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:14:37.957623 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:14:42.958442 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:14:48.961453 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:15:05,109] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=112558.8061 | _timers/batch_time=0.0054 | _timers/data_time=0.0042 | _timers/model_time=0.0011 | loss=0.0944\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118660.6164 | _timers/batch_time=0.0049 | _timers/data_time=0.0039 | _timers/model_time=0.0010 | loss=0.1072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:05.109247 139869237638976 logging.py:153] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=112558.8061 | _timers/batch_time=0.0054 | _timers/data_time=0.0042 | _timers/model_time=0.0011 | loss=0.0944\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118660.6164 | _timers/batch_time=0.0049 | _timers/data_time=0.0039 | _timers/model_time=0.0010 | loss=0.1072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):   3% 43/1608 [00:00<05:00,  5.21it/s, loss=0.084]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:05.973800 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  62% 991/1608 [00:11<00:05, 107.13it/s, loss=0.062]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:16.483069 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  98% 1572/1608 [00:18<00:00, 56.47it/s, loss=0.175] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:23.498250 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train): 100% 1608/1608 [00:19<00:00, 83.94it/s, loss=0.110]\n",
      "4/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 153.41it/s, loss=0.313]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:26.175103 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:15:26.175870 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:15:41.882728 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:15:45,530] \n",
      "4/10 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=112276.2091 | _timers/batch_time=0.0069 | _timers/data_time=0.0057 | _timers/model_time=0.0011 | loss=0.0895\n",
      "4/10 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120393.5368 | _timers/batch_time=0.0048 | _timers/data_time=0.0038 | _timers/model_time=0.0010 | loss=0.1083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:45.530226 139869237638976 logging.py:153] \n",
      "4/10 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=112276.2091 | _timers/batch_time=0.0069 | _timers/data_time=0.0057 | _timers/model_time=0.0011 | loss=0.0895\n",
      "4/10 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120393.5368 | _timers/batch_time=0.0048 | _timers/data_time=0.0038 | _timers/model_time=0.0010 | loss=0.1083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  23% 369/1608 [00:03<00:09, 129.20it/s, loss=0.046]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:48.938265 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  77% 1246/1608 [00:11<00:03, 91.35it/s, loss=0.106] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:15:56.948723 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train): 100% 1608/1608 [00:16<00:00, 95.29it/s, loss=0.062]\n",
      "5/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 150.28it/s, loss=0.324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:16:04.360232 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:16:04.360900 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:16:13.366167 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:16:20.370108 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:16:26,908] \n",
      "5/10 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=111920.5808 | _timers/batch_time=0.0054 | _timers/data_time=0.0042 | _timers/model_time=0.0012 | loss=0.0852\n",
      "5/10 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120370.8362 | _timers/batch_time=0.0049 | _timers/data_time=0.0039 | _timers/model_time=0.0010 | loss=0.1088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:16:26.908911 139869237638976 logging.py:153] \n",
      "5/10 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=111920.5808 | _timers/batch_time=0.0054 | _timers/data_time=0.0042 | _timers/model_time=0.0012 | loss=0.0852\n",
      "5/10 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=120370.8362 | _timers/batch_time=0.0049 | _timers/data_time=0.0039 | _timers/model_time=0.0010 | loss=0.1088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 * Epoch (train):  17% 281/1608 [00:02<00:10, 126.11it/s, loss=0.047]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:16:29.437052 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 * Epoch (train): 100% 1608/1608 [00:16<00:00, 99.99it/s, loss=0.063] \n",
      "6/10 * Epoch (valid): 100% 179/179 [00:01<00:00, 158.69it/s, loss=0.344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:16:44.857912 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:16:44.858759 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:16:45.859146 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:16:50.863534 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at 5 epoch\n",
      "[2020-03-02 18:16:59,211] \n",
      "6/10 * Epoch 6 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=117947.9777 | _timers/batch_time=0.0051 | _timers/data_time=0.0040 | _timers/model_time=0.0011 | loss=0.0809\n",
      "6/10 * Epoch 6 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=129336.7603 | _timers/batch_time=0.0046 | _timers/data_time=0.0036 | _timers/model_time=0.0010 | loss=0.1119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:16:59.211848 139869237638976 logging.py:153] \n",
      "6/10 * Epoch 6 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=117947.9777 | _timers/batch_time=0.0051 | _timers/data_time=0.0040 | _timers/model_time=0.0011 | loss=0.0809\n",
      "6/10 * Epoch 6 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=129336.7603 | _timers/batch_time=0.0046 | _timers/data_time=0.0036 | _timers/model_time=0.0010 | loss=0.1119\n",
      "I0302 18:16:59.215524 139869237638976 run_manager.py:1068] shutting down system stats and metadata service\n",
      "I0302 18:16:59.334183 139869237638976 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:16:59.336037 139861851895552 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:16:59.343093 139869237638976 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:16:59.344762 139869237638976 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/log.txt\n",
      "I0302 18:16:59.346306 139869237638976 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/train_log/events.out.tfevents.1583161960.UNIT-1482.8099.0\n",
      "I0302 18:16:59.348538 139869237638976 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/valid_log/events.out.tfevents.1583161978.UNIT-1482.8099.1\n",
      "I0302 18:16:59.350249 139869237638976 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/train_log\n",
      "I0302 18:16:59.351193 139869237638976 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/valid_log\n",
      "I0302 18:16:59.352037 139869237638976 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_151236-0ap4z17m/checkpoints\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top best models:\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora1_dup/checkpoints/train.3.pth\t0.1072\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora1_dup/checkpoints/train.4.pth\t0.1083\n"
     ]
    }
   ],
   "source": [
    "# use SupervisedWandbRunner runner to send statistics to wandb\n",
    "runner = dl.SupervisedWandbRunner(DEVICE)\n",
    "runner.train(model, \n",
    "             loaders=loaders,\n",
    "             num_epochs=num_epochs,\n",
    "             logdir=logdir,\n",
    "             criterion=nn.BCEWithLogitsLoss(),\n",
    "             optimizer=optimizer, \n",
    "             scheduler=scheduler,  \n",
    "             callbacks=[\n",
    "                dl.callbacks.CheckpointCallback(2), # save 2 best models (by epoch) into logdir\n",
    "                dl.callbacks.EarlyStoppingCallback(3), # stop training, if valid loss does not improve last 3 epochs\n",
    "             ],\n",
    "             # send current hyperparam values to wandb\n",
    "             monitoring_params={\n",
    "                 'entity': 'denaas', # your wandb username\n",
    "                 'project': 'text-augmentation', # project name\n",
    "                 'name': 'quora-embed-original', # name of the specific run\n",
    "                 'group': 'examples',\n",
    "                 'config': {\n",
    "                     'model': 'bigru',\n",
    "                     'optimizer': str(optimizer),\n",
    "                     'scheduler': 'plateau',\n",
    "                     'early_stop': 3,\n",
    "                     'vocab_size': len(TEXT.vocab.stoi),\n",
    "                     'h_size': h_size,\n",
    "                     'n_layers': n_layers,\n",
    "                     'dropout': dropout,\n",
    "                     'batch_size': batch_size,\n",
    "                     'embed_dim': embed_dim,\n",
    "                     'max_len': max_len,\n",
    "                 },\n",
    "             },\n",
    "#              check=True, # set if you want to check pipeline for correctness, without actual training\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.utils.unpack_checkpoint(dl.utils.load_checkpoint(f'{logdir}/checkpoints/best_full.pth'), model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6731092270903737 0.4875 0.9639730904008862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:17:11.432411 139869237638976 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:17:11.435420 139869237638976 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "I0302 18:17:12.047194 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n",
      "I0302 18:17:13.733177 139869237638976 run_manager.py:951] resuming run from id: UnVuOnYxOjBhcDR6MTdtOnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:17:13.756480 139869237638976 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "I0302 18:17:14.024659 139861354964736 run_manager.py:1048] saving patches\n",
      "I0302 18:17:14.610379 139861354964736 run_manager.py:1052] saving pip packages\n",
      "I0302 18:17:14.612020 139861354964736 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:17:14.613062 139861354964736 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "I0302 18:17:14.614069 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:17:14.615178 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:17:14.615746 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:17:14.616851 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/config.yaml\n",
      "I0302 18:17:14.628427 139869237638976 run_manager.py:1068] shutting down system stats and metadata service\n",
      "I0302 18:17:15.091732 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-history.jsonl\n",
      "I0302 18:17:15.094186 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-events.jsonl\n",
      "I0302 18:17:15.096913 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-summary.json\n",
      "I0302 18:17:15.101963 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/diff.patch\n",
      "I0302 18:17:15.106118 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/requirements.txt\n",
      "I0302 18:17:15.437516 139869237638976 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:17:16.092864 139861811877632 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_151236-0ap4z17m/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "# find threshold\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, valid_iter)\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in valid_iter])\n",
    "res = scipy.optimize.minimize(\n",
    "    lambda t: -metrics.f1_score(y_true, (y_proba >= t).astype(np.int)),\n",
    "    x0=0.5,\n",
    "    method='Nelder-Mead',\n",
    "    tol=1e-3,\n",
    ")\n",
    "threshold = res.x[0]\n",
    "\n",
    "\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, test_iter)\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in test_iter])\n",
    "\n",
    "auc_test = metrics.roc_auc_score(y_true, y_proba)\n",
    "f1_test = metrics.f1_score(y_true, (y_proba >= threshold).astype(np.int))\n",
    "\n",
    "print(f1_test, threshold, auc_test)\n",
    "wandb.log({'scores/f1': f1_test, 'scores/f1_threshold': threshold, 'scores/f1_auc': auc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
