{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "I0302 18:21:48.901045 140452000810816 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0302 18:21:49.590968 140452000810816 file_utils.py:57] TensorFlow version 2.0.0 available.\n",
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning:\n",
      "\n",
      "The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from catalyst import dl\n",
    "import wandb\n",
    "import joblib\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "mydir = '/data2/competitions/quora-insincere-questions-classification'\n",
    "SEED = 1234\n",
    "\n",
    "tqdm.pandas()\n",
    "# seed everything\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_size(model, trainable=True):\n",
    "    if trainable:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "    else:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    return psize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-apply-exponential-moving-average-decay-for-variables/10856\n",
    "class EMA():\n",
    "    def __init__(self, model, mu, level='batch', n=1):\n",
    "        \"\"\"\n",
    "        level: 'batch' or 'epoch'\n",
    "          'batch': Update params every n batches.\n",
    "          'epoch': Update params every epoch.\n",
    "        \"\"\"\n",
    "        # self.ema_model = copy.deepcopy(model)\n",
    "        self.mu = mu\n",
    "        self.level = level\n",
    "        self.n = n\n",
    "        self.cnt = self.n\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data\n",
    "\n",
    "    def _update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1 - self.mu) * param.data + self.mu * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def set_weights(self, ema_model):\n",
    "        for name, param in ema_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def on_batch_end(self, model):\n",
    "        if self.level is 'batch':\n",
    "            self.cnt -= 1\n",
    "            if self.cnt == 0:\n",
    "                self._update(model)\n",
    "                self.cnt = self.n\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.level is 'epoch':\n",
    "            self._update(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, h_size, n_layers, dropout, padding_idx, \n",
    "                 pretrained_embedding=None, fix_embedding=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.is_pretrained = pretrained_embedding is not None\n",
    "        \n",
    "        if self.is_pretrained:\n",
    "            self.embed = nn.Embedding.from_pretrained(pretrained_embedding, freeze=fix_embedding)\n",
    "            self.embed.padding_idx = padding_idx\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "            \n",
    "        self.embed_drop = nn.Dropout(dropout)\n",
    "            \n",
    "        self.gru = nn.GRU(embed_dim, h_size, n_layers, \n",
    "                          batch_first=True, \n",
    "                          bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*n_layers*h_size, h_size),\n",
    "            nn.BatchNorm1d(h_size),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(h_size, 1),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        if not self.is_pretrained:\n",
    "            d = self.embed.weight.size(1)\n",
    "            nn.init.uniform_(self.embed.weight, -1/np.sqrt(d), 1/np.sqrt(d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.embed_drop(x)\n",
    "        x, _ = self.gru(x)\n",
    "        x, _ = torch.max(x, 1)\n",
    "        x = self.out(x).squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "     \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "     def __init__(self, examples, fields, filter_pred=None):\n",
    "         \"\"\"\n",
    "         Create a dataset from a pandas dataframe of examples and Fields\n",
    "         Arguments:\n",
    "             examples pd.DataFrame: DataFrame of examples\n",
    "             fields {str: Field}: The Fields to use in this tuple. The\n",
    "                 string is a field name, and the Field is the associated field.\n",
    "             filter_pred (callable or None): use only exanples for which\n",
    "                 filter_pred(example) is true, or use all examples if None.\n",
    "                 Default is None\n",
    "         \"\"\"\n",
    "         self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "         if filter_pred is not None:\n",
    "             self.examples = filter(filter_pred, self.examples)\n",
    "         self.fields = dict(fields)\n",
    "         # Unpack field tuples\n",
    "         for n, f in list(self.fields.items()):\n",
    "             if isinstance(n, tuple):\n",
    "                 self.fields.update(zip(n, f))\n",
    "                 del self.fields[n]\n",
    "                    \n",
    "class SeriesExample(data.Example):\n",
    "     \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "     @classmethod\n",
    "     def fromSeries(cls, data, fields):\n",
    "         return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "     @classmethod\n",
    "     def fromdict(cls, data, fields):\n",
    "         ex = cls()\n",
    "\n",
    "         for key, field in fields.items():\n",
    "             if key not in data:\n",
    "                 raise ValueError(\"Specified key {} was not found in \"\n",
    "                 \"the input data\".format(key))\n",
    "             if field is not None:\n",
    "                 setattr(ex, key, field.preprocess(data[key]))\n",
    "             else:\n",
    "                 setattr(ex, key, data[key])\n",
    "         return ex\n",
    "\n",
    "# Simple wrapper to join torchtext and catalyst API\n",
    "\n",
    "class IteratorWrapper(torch.utils.data.DataLoader):\n",
    "    __initialized__ = False\n",
    "\n",
    "    def __init__(self, iter: iter):\n",
    "        self.batch_size = iter.batch_size\n",
    "        self.num_workers = 1\n",
    "        self.collate_fn = None\n",
    "        self.pin_memory = False\n",
    "        self.drop_last = False\n",
    "        self.timeout = 0\n",
    "        self.worker_init_fn = None\n",
    "        self.sampler = iter\n",
    "        self.batch_sampler = iter\n",
    "        self.__initialized__ = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(lambda batch: {\n",
    "                    'features': batch.text,\n",
    "                    'targets': batch.target,\n",
    "                }, self.batch_sampler.__iter__())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "puncts = ',.\":)(-!?|;\\'$&/[]>%=#*+\\\\•~@£·_{}©^®`<→°€™›♥←×§″′Â█½à…“★”–●â►−¢²¬░¶↑±¿▾═¦║\\\n",
    "―¥▓—‹─▒：¼⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸¾Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡√'\n",
    "\n",
    "\n",
    "def clean_text(x, puncts=puncts): #добавляет пробелы вокруг пунктуации\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4924ca991649178f6ab9b05dd30f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9221e3ee9e71449c859154f2fe3d86d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "920bcfcc46d14d29b4068e9c24f7476e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fee16e14bc84638b07ac6e7efa3e8cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=914280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c930a9ba47264556996b3b46d20c2d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=914280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8085ee60084c42856280f1588087bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=914280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{mydir}/train.csv', index_col=0).reset_index(drop=True)\n",
    "df_train = df_train.rename(columns={'question_text': 'text'})\n",
    "\n",
    "df_train['text'] = df_train['text'].progress_apply(str.lower)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_text)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_numbers)\n",
    "\n",
    "df_train, df_test = train_test_split(df_train, train_size=0.7, random_state=SEED)\n",
    "\n",
    "augmented = pd.read_csv(f'{mydir}/augmented_fairseq.csv', index_col=0)\n",
    "augmented = augmented.rename(columns={'question_text': 'text'})\n",
    "augmented['text'] = augmented['text'].str[2:-2]\n",
    "\n",
    "augmented['text'] = augmented['text'].progress_apply(str.lower)\n",
    "augmented['text'] = augmented['text'].progress_apply(clean_text)\n",
    "augmented['text'] = augmented['text'].progress_apply(clean_numbers)\n",
    "\n",
    "df_train = pd.concat([df_train, augmented]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1645708, 182857)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 50\n",
    "\n",
    "TEXT = data.Field(\n",
    "#     include_lengths=True,\n",
    "                  postprocessing = lambda batch, vocab: [x[:max_len] for x in batch],\n",
    "                  lower=True,\n",
    "                  tokenize='spacy', \n",
    "                  tokenizer_language='en', \n",
    "                  batch_first=True\n",
    "                 )\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train = DataFrameDataset(df_train, fields={'text': TEXT, 'target': LABEL})\n",
    "test = DataFrameDataset(df_test, fields={'text': TEXT, 'target': LABEL})\n",
    "\n",
    "TEXT.build_vocab(train, test, min_freq=5)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "train, valid = train.split(split_ratio=0.9)\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61101"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_size = 128\n",
    "num_epochs = 10 \n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "embed_dim = 128\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n",
    "                                                               batch_size=batch_size, \n",
    "                                                               sort_key=lambda x: len(x.text),\n",
    "                                                               sort=True,\n",
    "                                                               device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_iter = IteratorWrapper(train_iter)\n",
    "valid_iter = IteratorWrapper(valid_iter)\n",
    "test_iter = IteratorWrapper(test_iter)\n",
    "loaders = {'train': train_iter, 'valid': valid_iter}\n",
    "\n",
    "\n",
    "model = GRUModel(vocab_size=vocab_size, \n",
    "                 embed_dim=embed_dim, \n",
    "                 h_size=h_size, \n",
    "                 n_layers=n_layers, \n",
    "                 dropout=dropout, \n",
    "                 padding_idx=TEXT.vocab.stoi['<pad>'], \n",
    "                 pretrained_embedding=None, \n",
    "                 fix_embedding=False)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=2, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = f'{mydir}/log_quora2_dup'\n",
    "!rm -rf {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/denaas/text-augmentation\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/denaas/text-augmentation/runs/wq8ax5n9\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation/runs/wq8ax5n9</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:40:30.552883 140452000810816 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:40:30.554684 140452000810816 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:40:30.840525 140452000810816 run_manager.py:951] resuming run from id: UnVuOnYxOndxOGF4NW45OnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:40:30.849404 140452000810816 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:40:31.206304 140444893705984 run_manager.py:1048] saving patches\n",
      "I0302 18:40:31.246901 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/config.yaml\n",
      "I0302 18:40:31.613936 140444893705984 run_manager.py:1052] saving pip packages\n",
      "I0302 18:40:31.615559 140444893705984 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:40:31.616397 140444893705984 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora2_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:40:31.947334 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:40:31.948861 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n",
      "I0302 18:40:31.949668 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n",
      "I0302 18:40:31.950598 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n",
      "I0302 18:40:32.246330 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/diff.patch\n",
      "I0302 18:40:32.247398 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  49% 1570/3215 [00:13<00:14, 110.81it/s, loss=0.071]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:40:47.314888 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  88% 2816/3215 [00:26<00:04, 91.29it/s, loss=0.148] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:40:59.331222 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  98% 3138/3215 [00:30<00:01, 67.80it/s, loss=0.235]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:03.343275 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 3215/3215 [00:31<00:00, 102.78it/s, loss=0.430]\n",
      "1/10 * Epoch (valid): 100% 358/358 [00:01<00:00, 180.61it/s, loss=0.070]\n",
      "[2020-03-02 18:41:06,844] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118954.7763 | _timers/batch_time=0.0051 | _timers/data_time=0.0040 | _timers/model_time=0.0011 | loss=0.1188\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=131461.3101 | _timers/batch_time=0.0046 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:06.844314 140452000810816 logging.py:153] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118954.7763 | _timers/batch_time=0.0051 | _timers/data_time=0.0040 | _timers/model_time=0.0011 | loss=0.1188\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=131461.3101 | _timers/batch_time=0.0046 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):   0% 0/3215 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:07.432280 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:41:07.582064 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  45% 1456/3215 [00:12<00:15, 111.38it/s, loss=0.046]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:19.435553 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  80% 2582/3215 [00:23<00:06, 91.13it/s, loss=0.116] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:34.551876 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  94% 3036/3215 [00:32<00:02, 81.65it/s, loss=0.196]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:39.557515 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train): 100% 3215/3215 [00:35<00:00, 90.93it/s, loss=0.229]\n",
      "2/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 176.30it/s, loss=0.080]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:44.559857 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:41:44.561057 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:41:46,281] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119979.5417 | _timers/batch_time=0.0063 | _timers/data_time=0.0052 | _timers/model_time=0.0011 | loss=0.0919\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=124282.3685 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:46.281005 140452000810816 logging.py:153] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119979.5417 | _timers/batch_time=0.0063 | _timers/data_time=0.0052 | _timers/model_time=0.0011 | loss=0.0919\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=124282.3685 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  29% 922/3215 [00:08<00:18, 126.09it/s, loss=0.051]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:41:54.625303 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  68% 2198/3215 [00:19<00:08, 113.94it/s, loss=0.047]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:05.633713 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  84% 2688/3215 [00:24<00:05, 91.19it/s, loss=0.093] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:10.647188 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train): 100% 3215/3215 [00:31<00:00, 103.59it/s, loss=0.094]\n",
      "3/10 * Epoch (valid): 100% 358/358 [00:01<00:00, 183.67it/s, loss=0.097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:19.656490 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:42:19.660100 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:42:20,789] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119077.5507 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0714\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=131287.3993 | _timers/batch_time=0.0045 | _timers/data_time=0.0036 | _timers/model_time=0.0009 | loss=0.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:20.789206 140452000810816 logging.py:153] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119077.5507 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0714\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=131287.3993 | _timers/batch_time=0.0045 | _timers/data_time=0.0036 | _timers/model_time=0.0009 | loss=0.1749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  20% 633/3215 [00:06<00:23, 111.07it/s, loss=0.032]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:26.930310 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  57% 1845/3215 [00:16<00:12, 109.80it/s, loss=0.031]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:36.942469 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  77% 2480/3215 [00:22<00:07, 93.90it/s, loss=0.051] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:42.945572 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train): 100% 3215/3215 [00:30<00:00, 104.12it/s, loss=0.110]\n",
      "4/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 174.11it/s, loss=0.074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:53.969449 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:42:53.970352 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:42:54,682] \n",
      "4/10 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118463.0336 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0555\n",
      "4/10 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=125565.9315 | _timers/batch_time=0.0048 | _timers/data_time=0.0038 | _timers/model_time=0.0009 | loss=0.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:54.682512 140452000810816 logging.py:153] \n",
      "4/10 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118463.0336 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0555\n",
      "4/10 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=125565.9315 | _timers/batch_time=0.0048 | _timers/data_time=0.0038 | _timers/model_time=0.0009 | loss=0.1756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  13% 403/3215 [00:04<00:22, 125.77it/s, loss=0.037]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:42:59.096154 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  43% 1379/3215 [00:12<00:16, 109.75it/s, loss=0.020]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:43:07.103767 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  71% 2273/3215 [00:20<00:08, 104.81it/s, loss=0.037]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:43:15.113206 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train): 100% 3215/3215 [00:31<00:00, 103.30it/s, loss=0.052]\n",
      "5/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 177.50it/s, loss=0.137]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:43:28.123273 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:43:28.126941 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at 4 epoch\n",
      "[2020-03-02 18:43:28,897] \n",
      "5/10 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=117992.3068 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0458\n",
      "5/10 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=126070.1315 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0010 | loss=0.1956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:43:28.897202 140452000810816 logging.py:153] \n",
      "5/10 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=117992.3068 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0458\n",
      "5/10 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=126070.1315 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0010 | loss=0.1956\n",
      "I0302 18:43:28.902315 140452000810816 run_manager.py:1068] shutting down system stats and metadata service\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top best models:\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora2_dup/checkpoints/train.2.pth\t0.1483\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora2_dup/checkpoints/train.1.pth\t0.1522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:43:29.124420 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n",
      "I0302 18:43:29.126821 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/log.txt\n",
      "I0302 18:43:29.129561 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/train_log/events.out.tfevents.1583163633.UNIT-1482.3385.0\n",
      "I0302 18:43:29.132676 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/valid_log/events.out.tfevents.1583163664.UNIT-1482.3385.1\n",
      "I0302 18:43:29.133514 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/checkpoints\n",
      "I0302 18:43:29.133874 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/valid_log\n",
      "I0302 18:43:29.134430 140445267433216 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_154029-wq8ax5n9/train_log\n",
      "I0302 18:43:29.817255 140452000810816 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:43:30.125357 140445267433216 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "# use SupervisedWandbRunner runner to send statistics to wandb\n",
    "runner = dl.SupervisedWandbRunner(DEVICE)\n",
    "runner.train(model, \n",
    "             loaders=loaders,\n",
    "             num_epochs=num_epochs,\n",
    "             logdir=logdir,\n",
    "             criterion=nn.BCEWithLogitsLoss(),\n",
    "             optimizer=optimizer, \n",
    "             scheduler=scheduler,  \n",
    "             callbacks=[\n",
    "                dl.callbacks.CheckpointCallback(2), # save 2 best models (by epoch) into logdir\n",
    "                dl.callbacks.EarlyStoppingCallback(3), # stop training, if valid loss does not improve last 3 epochs\n",
    "             ],\n",
    "             # send current hyperparam values to wandb\n",
    "             monitoring_params={\n",
    "                 'entity': 'denaas', # your wandb username\n",
    "                 'project': 'text-augmentation', # project name\n",
    "                 'name': 'quora-noembed-dup', # name of the specific run\n",
    "                 'group': 'examples',\n",
    "                 'config': {\n",
    "                     'model': 'bigru',\n",
    "                     'optimizer': str(optimizer),\n",
    "                     'scheduler': 'plateau',\n",
    "                     'early_stop': 3,\n",
    "                     'vocab_size': vocab_size,\n",
    "                     'h_size': h_size,\n",
    "                     'n_layers': n_layers,\n",
    "                     'dropout': dropout,\n",
    "                     'batch_size': batch_size,\n",
    "                     'embed_dim': embed_dim,\n",
    "                     'max_len': max_len,\n",
    "                 },\n",
    "             },\n",
    "#              check=True, # set if you want to check pipeline for correctness, without actual training\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.utils.unpack_checkpoint(dl.utils.load_checkpoint(f'{logdir}//checkpoints/best_full.pth'), model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6459476392079434 0.7101562500000005 0.9594608178612632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:43:47.385812 140452000810816 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:43:47.389264 140452000810816 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "I0302 18:43:47.637253 140452000810816 run_manager.py:951] resuming run from id: UnVuOnYxOndxOGF4NW45OnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:43:47.660762 140452000810816 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "I0302 18:43:47.962509 140445244200704 run_manager.py:1048] saving patches\n",
      "I0302 18:43:48.007071 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n",
      "I0302 18:43:48.487831 140445244200704 run_manager.py:1052] saving pip packages\n",
      "I0302 18:43:48.489408 140445244200704 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:43:48.490300 140445244200704 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "I0302 18:43:48.491509 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n",
      "I0302 18:43:48.492563 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n",
      "I0302 18:43:48.493098 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:43:48.494139 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/config.yaml\n",
      "I0302 18:43:48.507304 140452000810816 run_manager.py:1068] shutting down system stats and metadata service\n",
      "I0302 18:43:49.008320 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/diff.patch\n",
      "I0302 18:43:49.010757 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-history.jsonl\n",
      "I0302 18:43:49.013916 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-events.jsonl\n",
      "I0302 18:43:49.016070 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-summary.json\n",
      "I0302 18:43:49.016911 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/requirements.txt\n",
      "I0302 18:43:49.388295 140452000810816 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:43:50.009249 140445275825920 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_154029-wq8ax5n9/wandb-metadata.json\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "# find threshold\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, valid_iter)\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in valid_iter])\n",
    "res = scipy.optimize.minimize(\n",
    "    lambda t: -metrics.f1_score(y_true, (y_proba >= t).astype(np.int)),\n",
    "    x0=0.5,\n",
    "    method='Nelder-Mead',\n",
    "    tol=1e-3,\n",
    ")\n",
    "threshold = res.x[0]\n",
    "\n",
    "\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, test_iter)\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in test_iter])\n",
    "\n",
    "auc_test = metrics.roc_auc_score(y_true, y_proba)\n",
    "f1_test = metrics.f1_score(y_true, (y_proba >= threshold).astype(np.int))\n",
    "\n",
    "print(f1_test, threshold, auc_test)\n",
    "wandb.log({'scores/f1': f1_test, 'scores/f1_threshold': threshold, 'scores/f1_auc': auc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
