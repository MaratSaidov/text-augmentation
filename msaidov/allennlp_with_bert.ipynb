{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "allennlp-with-bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZHcX2Typml0",
        "colab_type": "text"
      },
      "source": [
        "# Technical cells"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFxRLU4eprQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoHlApBSpDEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "66c8ac05-922a-489d-f809-6a94e5f544b2"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import allennlp\n",
        "print(\"Torchtext Version:\", torchtext.__version__)\n",
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"AllenNLP Version:\", allennlp.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torchtext Version: 0.3.1\n",
            "PyTorch Version: 1.4.0\n",
            "AllenNLP Version: 0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPfuk2JpxIt",
        "colab_type": "text"
      },
      "source": [
        "# Provide changed version of SNLI Reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mi8Kp_PuHqt",
        "colab_type": "text"
      },
      "source": [
        "For natural language inference task BERT requires the following construction as an input: <br>\n",
        "`[CLS] I am your father . [SEP] No . No ! That â€™ s not true ! [SEP]` <br>\n",
        "We changed the default definition of SNLI Reader from AllenNLP in order to provide such a data representation.\n",
        "\n",
        "The following code placed separately in `bert_snli.py` to use utility:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPsA83shplMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "from typing import Dict\n",
        "\n",
        "from allennlp.data.dataset_readers import SnliReader\n",
        "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
        "from allennlp.data.fields import Field\n",
        "from allennlp.data.fields import LabelField\n",
        "from allennlp.data.fields import TextField\n",
        "from allennlp.data.instance import Instance\n",
        "from allennlp.data.token_indexers import TokenIndexer\n",
        "from allennlp.data.tokenizers import Tokenizer\n",
        "from overrides import overrides\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "@DatasetReader.register(\"bert_snli\")\n",
        "class BertSnliReader(SnliReader):\n",
        "    \"\"\"\n",
        "    Reads a file from the Stanford Natural Language Inference (SNLI) dataset.  This data is\n",
        "    formatted as jsonl, one json-formatted instance per line.  The keys in the data are\n",
        "    \"gold_label\", \"sentence1\", and \"sentence2\".  We convert these keys into fields named \"label\",\n",
        "    and \"tokens\".\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tokenizer : ``Tokenizer``, optional (default=``SpacyTokenizer()``)\n",
        "        We use this ``Tokenizer`` for both the premise and the hypothesis.  See :class:`Tokenizer`.\n",
        "    token_indexers : ``Dict[str, TokenIndexer]``, optional (default=``{\"tokens\": SingleIdTokenIndexer()}``)\n",
        "        We similarly use this for both the premise and the hypothesis.  See :class:`TokenIndexer`.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer: Tokenizer = None,\n",
        "        token_indexers: Dict[str, TokenIndexer] = None,\n",
        "        lazy: bool = False,\n",
        "    ) -> None:\n",
        "        super(BertSnliReader, self).__init__(tokenizer, token_indexers, lazy)\n",
        "\n",
        "    @overrides\n",
        "    def text_to_instance(\n",
        "        self,  # type: ignore\n",
        "        premise: str,\n",
        "        hypothesis: str,\n",
        "        label: str = None,\n",
        "    ) -> Instance:\n",
        "\n",
        "        fields: Dict[str, Field] = {}\n",
        "        premise_tokens = self._tokenizer.tokenize(premise)\n",
        "        hypothesis_tokens = self._tokenizer.tokenize(hypothesis)\n",
        "        # Here, we join the premise with the hypothesis, dropping the CLS token from the hypothesis.        \n",
        "        # This gives us our desired inputs: \"[CLS] premise [SEP] hypothesis [SEP]\"\n",
        "        tokens = premise_tokens + hypothesis_tokens[1:]\n",
        "        fields[\"tokens\"] = TextField(tokens, self._token_indexers)\n",
        "        if label:\n",
        "            fields[\"label\"] = LabelField(label)\n",
        "\n",
        "        return Instance(fields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXqvgH-M9Bn9",
        "colab_type": "text"
      },
      "source": [
        "Configuration of training is modeled in `train.jsonnet` file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWWm2Easpzup",
        "colab_type": "text"
      },
      "source": [
        "# Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BWi_ejIp7Vb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "216b6922-210d-4b66-db39-37abc358acb1"
      },
      "source": [
        "!allennlp train train.jsonnet --include-package bert_snli -s ./bert-logging -f"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-07 19:02:03,339 - INFO - pytorch_pretrained_bert.modeling - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2020-04-07 19:02:03,762 - INFO - pytorch_transformers.modeling_bert - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2020-04-07 19:02:03,765 - INFO - pytorch_transformers.modeling_xlnet - Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
            "2020-04-07 19:02:04,138 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2020-04-07 19:02:04,139 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2020-04-07 19:02:04,140 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2020-04-07 19:02:04,140 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
            "2020-04-07 19:02:04,218 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2020-04-07 19:02:04,218 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2020-04-07 19:02:04,218 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2020-04-07 19:02:04,242 - INFO - allennlp.common.checks - Pytorch version: 1.4.0\n",
            "2020-04-07 19:02:04,244 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2020-04-07 19:02:04,244 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2020-04-07 19:02:04,244 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'lazy': False, 'token_indexers': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}, 'tokenizer': {'do_lowercase': True, 'model_name': 'bert-base-uncased', 'type': 'pretrained_transformer'}, 'type': 'bert_snli'} and extras set()\n",
            "2020-04-07 19:02:04,244 - INFO - allennlp.common.params - dataset_reader.type = bert_snli\n",
            "2020-04-07 19:02:04,244 - INFO - allennlp.common.from_params - instantiating class <class 'bert_snli.BertSnliReader'> from params {'lazy': False, 'token_indexers': {'bert': {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'}}, 'tokenizer': {'do_lowercase': True, 'model_name': 'bert-base-uncased', 'type': 'pretrained_transformer'}} and extras set()\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.tokenizer.Tokenizer'> from params {'do_lowercase': True, 'model_name': 'bert-base-uncased', 'type': 'pretrained_transformer'} and extras set()\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.tokenizers.pretrained_transformer_tokenizer.PretrainedTransformerTokenizer'> from params {'do_lowercase': True, 'model_name': 'bert-base-uncased'} and extras set()\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = bert-base-uncased\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.params - dataset_reader.tokenizer.do_lowercase = True\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.params - dataset_reader.tokenizer.start_tokens = None\n",
            "2020-04-07 19:02:04,245 - INFO - allennlp.common.params - dataset_reader.tokenizer.end_tokens = None\n",
            "2020-04-07 19:02:04,546 - INFO - pytorch_transformers.tokenization_utils - loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained'} and extras set()\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.type = bert-pretrained\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.from_params - instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'pretrained_model': 'bert-base-uncased'} and extras set()\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.use_starting_offsets = False\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.do_lowercase = True\n",
            "2020-04-07 19:02:04,648 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.never_lowercase = None\n",
            "2020-04-07 19:02:04,649 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.max_pieces = 512\n",
            "2020-04-07 19:02:04,649 - INFO - allennlp.common.params - dataset_reader.token_indexers.bert.truncate_long_sequences = True\n",
            "2020-04-07 19:02:04,926 - INFO - pytorch_pretrained_bert.tokenization - loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2020-04-07 19:02:04,957 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2020-04-07 19:02:04,957 - INFO - allennlp.common.params - train_data_path = drive/My Drive/text-augmentation/snli/snli_1.0_train.jsonl\n",
            "2020-04-07 19:02:04,957 - INFO - allennlp.training.util - Reading training data from drive/My Drive/text-augmentation/snli/snli_1.0_train.jsonl\n",
            "0it [00:00, ?it/s]2020-04-07 19:02:05,255 - INFO - allennlp.data.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: drive/My Drive/text-augmentation/snli/snli_1.0_train.jsonl\n",
            "549367it [03:57, 2315.03it/s]\n",
            "2020-04-07 19:06:02,263 - INFO - allennlp.common.params - validation_data_path = drive/My Drive/text-augmentation/snli/snli_1.0_dev.jsonl\n",
            "2020-04-07 19:06:02,263 - INFO - allennlp.training.util - Reading validation data from drive/My Drive/text-augmentation/snli/snli_1.0_dev.jsonl\n",
            "0it [00:00, ?it/s]2020-04-07 19:06:02,265 - INFO - allennlp.data.dataset_readers.snli - Reading SNLI instances from jsonl dataset at: drive/My Drive/text-augmentation/snli/snli_1.0_dev.jsonl\n",
            "9842it [00:06, 1564.38it/s]\n",
            "2020-04-07 19:06:08,555 - INFO - allennlp.common.params - test_data_path = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.training.trainer_pieces - From dataset instances, validation, train will be considered for vocabulary creation.\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.type = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.extend = False\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.directory_path = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.min_count = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.max_vocab_size = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.pretrained_files = {}\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.min_pretrained_embeddings = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.only_include_pretrained_words = False\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.common.params - vocabulary.tokens_to_add = None\n",
            "2020-04-07 19:06:09,433 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "559209it [00:02, 201310.12it/s]\n",
            "2020-04-07 19:06:12,212 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.model.Model'> from params {'bert_model': 'bert-base-uncased', 'dropout': 0.1, 'num_labels': 3, 'type': 'bert_for_classification'} and extras {'vocab'}\n",
            "2020-04-07 19:06:12,212 - INFO - allennlp.common.params - model.type = bert_for_classification\n",
            "2020-04-07 19:06:12,212 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.models.bert_for_classification.BertForClassification'> from params {'bert_model': 'bert-base-uncased', 'dropout': 0.1, 'num_labels': 3} and extras {'vocab'}\n",
            "2020-04-07 19:06:12,213 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
            "2020-04-07 19:06:12,213 - INFO - allennlp.common.params - model.dropout = 0.1\n",
            "2020-04-07 19:06:12,213 - INFO - allennlp.common.params - model.num_labels = 3\n",
            "2020-04-07 19:06:12,213 - INFO - allennlp.common.params - model.index = bert\n",
            "2020-04-07 19:06:12,213 - INFO - allennlp.common.params - model.label_namespace = labels\n",
            "2020-04-07 19:06:12,213 - INFO - allennlp.common.params - model.trainable = True\n",
            "2020-04-07 19:06:12,483 - INFO - pytorch_pretrained_bert.file_utils - https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpr5e3hb4d\n",
            "100%|##########| 407873900/407873900 [00:12<00:00, 33443058.10B/s]\n",
            "2020-04-07 19:06:25,026 - INFO - pytorch_pretrained_bert.file_utils - copying /tmp/tmpr5e3hb4d to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "2020-04-07 19:06:26,201 - INFO - pytorch_pretrained_bert.file_utils - creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "2020-04-07 19:06:26,201 - INFO - pytorch_pretrained_bert.file_utils - removing temp file /tmp/tmpr5e3hb4d\n",
            "2020-04-07 19:06:26,243 - INFO - pytorch_pretrained_bert.modeling - loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "2020-04-07 19:06:26,244 - INFO - pytorch_pretrained_bert.modeling - extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp19phe2ry\n",
            "2020-04-07 19:06:30,173 - INFO - pytorch_pretrained_bert.modeling - Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2020-04-07 19:06:32,048 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2020-04-07 19:06:32,048 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2020-04-07 19:06:32,048 - INFO - allennlp.nn.initializers -    bias\n",
            "2020-04-07 19:06:32,049 - INFO - allennlp.nn.initializers -    weight\n",
            "2020-04-07 19:06:32,050 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.data_iterator.DataIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']], 'type': 'bucket'} and extras set()\n",
            "2020-04-07 19:06:32,050 - INFO - allennlp.common.params - iterator.type = bucket\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.from_params - instantiating class <class 'allennlp.data.iterators.bucket_iterator.BucketIterator'> from params {'batch_size': 32, 'sorting_keys': [['tokens', 'num_tokens']]} and extras set()\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.sorting_keys = [['tokens', 'num_tokens']]\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.padding_noise = 0.1\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.biggest_batch_first = False\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.batch_size = 32\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.instances_per_epoch = None\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.max_instances_in_memory = None\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.cache_instances = False\n",
            "2020-04-07 19:06:32,051 - INFO - allennlp.common.params - iterator.track_epoch = False\n",
            "2020-04-07 19:06:32,052 - INFO - allennlp.common.params - iterator.maximum_samples_per_batch = None\n",
            "2020-04-07 19:06:32,052 - INFO - allennlp.common.params - iterator.skip_smaller_batches = False\n",
            "2020-04-07 19:06:32,052 - INFO - allennlp.common.params - validation_iterator = None\n",
            "2020-04-07 19:06:32,052 - INFO - allennlp.common.params - trainer.no_grad = ()\n",
            "2020-04-07 19:06:32,053 - INFO - allennlp.training.trainer_pieces - Following parameters are Frozen  (without gradient):\n",
            "2020-04-07 19:06:32,053 - INFO - allennlp.training.trainer_pieces - Following parameters are Tunable (with gradient):\n",
            "2020-04-07 19:06:32,053 - INFO - allennlp.training.trainer_pieces - bert_model.embeddings.word_embeddings.weight\n",
            "2020-04-07 19:06:32,053 - INFO - allennlp.training.trainer_pieces - bert_model.embeddings.position_embeddings.weight\n",
            "2020-04-07 19:06:32,053 - INFO - allennlp.training.trainer_pieces - bert_model.embeddings.token_type_embeddings.weight\n",
            "2020-04-07 19:06:32,053 - INFO - allennlp.training.trainer_pieces - bert_model.embeddings.LayerNorm.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.embeddings.LayerNorm.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.self.query.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.self.query.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.self.key.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.self.key.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.self.value.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.self.value.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.output.dense.weight\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.output.dense.bias\n",
            "2020-04-07 19:06:32,054 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.self.query.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.self.query.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.self.key.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.self.key.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.self.value.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.self.value.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.output.dense.weight\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.output.dense.bias\n",
            "2020-04-07 19:06:32,055 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.self.query.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.self.query.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.self.key.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.self.key.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.self.value.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.self.value.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.output.dense.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.output.dense.bias\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,056 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.2.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.self.query.weight\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.self.query.bias\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.self.key.weight\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.self.key.bias\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.self.value.weight\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.self.value.bias\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,057 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.output.dense.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.output.dense.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.3.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.self.query.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.self.query.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.self.key.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.self.key.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.self.value.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.self.value.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,058 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.output.dense.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.output.dense.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.4.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.self.query.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.self.query.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.self.key.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.self.key.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.self.value.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.self.value.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,059 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.output.dense.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.output.dense.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.5.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.self.query.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.self.query.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.self.key.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.self.key.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.self.value.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.self.value.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.output.dense.weight\n",
            "2020-04-07 19:06:32,060 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.output.dense.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.6.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.self.query.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.self.query.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.self.key.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.self.key.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.self.value.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.self.value.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.output.dense.weight\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.output.dense.bias\n",
            "2020-04-07 19:06:32,061 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.7.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.self.query.weight\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.self.query.bias\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.self.key.weight\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.self.key.bias\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.self.value.weight\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.self.value.bias\n",
            "2020-04-07 19:06:32,062 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.output.dense.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.output.dense.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.8.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.self.query.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.self.query.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.self.key.weight\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.self.key.bias\n",
            "2020-04-07 19:06:32,103 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.self.value.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.self.value.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.output.dense.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.output.dense.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.9.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.self.query.weight\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.self.query.bias\n",
            "2020-04-07 19:06:32,104 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.self.key.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.self.key.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.self.value.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.self.value.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.output.dense.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.output.dense.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.10.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,105 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.self.query.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.self.query.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.self.key.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.self.key.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.self.value.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.self.value.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.output.dense.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.output.dense.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.intermediate.dense.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.intermediate.dense.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.output.dense.weight\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.output.dense.bias\n",
            "2020-04-07 19:06:32,106 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.output.LayerNorm.weight\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.training.trainer_pieces - bert_model.encoder.layer.11.output.LayerNorm.bias\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.training.trainer_pieces - bert_model.pooler.dense.weight\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.training.trainer_pieces - bert_model.pooler.dense.bias\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.training.trainer_pieces - _classification_layer.weight\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.training.trainer_pieces - _classification_layer.bias\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.common.params - trainer.patience = None\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.common.params - trainer.validation_metric = +accuracy\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.common.params - trainer.shuffle = True\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.common.params - trainer.num_epochs = 5\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2020-04-07 19:06:32,107 - INFO - allennlp.common.params - trainer.grad_norm = 1\n",
            "2020-04-07 19:06:32,108 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2020-04-07 19:06:32,108 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None\n",
            "2020-04-07 19:06:32,108 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2020-04-07 19:06:41,212 - INFO - allennlp.common.params - trainer.optimizer.type = bert_adam\n",
            "2020-04-07 19:06:41,212 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2020-04-07 19:06:41,212 - INFO - allennlp.training.optimizers - Number of trainable parameters: 109484547\n",
            "2020-04-07 19:06:41,213 - INFO - allennlp.common.params - trainer.optimizer.infer_type_and_cast = True\n",
            "2020-04-07 19:06:41,213 - INFO - allennlp.common.params - Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
            "2020-04-07 19:06:41,213 - INFO - allennlp.common.params - CURRENTLY DEFINED PARAMETERS: \n",
            "2020-04-07 19:06:41,213 - INFO - allennlp.common.params - trainer.optimizer.lr = 2e-05\n",
            "2020-04-07 19:06:41,213 - INFO - allennlp.common.registrable - instantiating registered subclass bert_adam of <class 'allennlp.training.optimizers.Optimizer'>\n",
            "2020-04-07 19:06:41,213 - WARNING - pytorch_pretrained_bert.optimization - t_total value of -1 results in schedule not being applied\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.num_serialized_models_to_keep = 1\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.keep_serialized_model_every_num_seconds = None\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.model_save_interval = None\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.summary_interval = 100\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.histogram_interval = None\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.should_log_parameter_statistics = True\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.should_log_learning_rate = False\n",
            "2020-04-07 19:06:41,214 - INFO - allennlp.common.params - trainer.log_batch_size_period = None\n",
            "2020-04-07 19:06:41,214 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "2020-04-07 19:06:41,216 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2020-04-07 19:06:41,216 - INFO - allennlp.training.trainer - Epoch 0/4\n",
            "2020-04-07 19:06:41,216 - INFO - allennlp.training.trainer - Peak CPU memory usage MB: 6326.3\n",
            "2020-04-07 19:06:41,342 - INFO - allennlp.training.trainer - GPU 0 memory usage MB: 1005\n",
            "2020-04-07 19:06:41,344 - INFO - allennlp.training.trainer - Training\n",
            "accuracy: 0.8007, loss: 0.4996 ||:  11%|#1        | 1934/17168 [14:03<1:40:42,  2.52it/s]Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/allennlp\", line 8, in <module>\n",
            "    sys.exit(run())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/run.py\", line 18, in run\n",
            "    main(prog=\"allennlp\")\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/__init__.py\", line 102, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 124, in train_model_from_args\n",
            "    args.cache_prefix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 168, in train_model_from_file\n",
            "    cache_directory, cache_prefix)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/commands/train.py\", line 252, in train_model\n",
            "    metrics = trainer.train()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\", line 478, in train\n",
            "    train_metrics = self._train_epoch(epoch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\", line 352, in _train_epoch\n",
            "    self.optimizer.step()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py\", line 271, in step\n",
            "    clip_grad_norm_(p, group['max_grad_norm'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/utils/clip_grad.py\", line 33, in clip_grad_norm_\n",
            "    total_norm += param_norm.item() ** norm_type\n",
            "KeyboardInterrupt\n",
            "accuracy: 0.8007, loss: 0.4996 ||:  11%|#1        | 1934/17168 [14:12<1:51:58,  2.27it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl1shQCIFrZA",
        "colab_type": "text"
      },
      "source": [
        "Accuracy and Loss: `accuracy: 0.8007, loss: 0.4996`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNJJoPOT9_cZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}