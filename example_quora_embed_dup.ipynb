{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "I0302 18:19:43.302976 140359865444160 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0302 18:19:43.909866 140359865444160 file_utils.py:57] TensorFlow version 2.0.0 available.\n",
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning:\n",
      "\n",
      "The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from catalyst import dl\n",
    "import wandb\n",
    "import joblib\n",
    "\n",
    "\n",
    "DEVICE = 'cuda'\n",
    "mydir = '/data2/competitions/quora-insincere-questions-classification'\n",
    "SEED = 1234\n",
    "\n",
    "tqdm.pandas()\n",
    "# seed everything\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_param_size(model, trainable=True):\n",
    "    if trainable:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "    else:\n",
    "        psize = np.sum([np.prod(p.size()) for p in model.parameters()])\n",
    "    return psize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-apply-exponential-moving-average-decay-for-variables/10856\n",
    "class EMA():\n",
    "    def __init__(self, model, mu, level='batch', n=1):\n",
    "        \"\"\"\n",
    "        level: 'batch' or 'epoch'\n",
    "          'batch': Update params every n batches.\n",
    "          'epoch': Update params every epoch.\n",
    "        \"\"\"\n",
    "        # self.ema_model = copy.deepcopy(model)\n",
    "        self.mu = mu\n",
    "        self.level = level\n",
    "        self.n = n\n",
    "        self.cnt = self.n\n",
    "        self.shadow = {}\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data\n",
    "\n",
    "    def _update(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                new_average = (1 - self.mu) * param.data + self.mu * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def set_weights(self, ema_model):\n",
    "        for name, param in ema_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def on_batch_end(self, model):\n",
    "        if self.level is 'batch':\n",
    "            self.cnt -= 1\n",
    "            if self.cnt == 0:\n",
    "                self._update(model)\n",
    "                self.cnt = self.n\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        if self.level is 'epoch':\n",
    "            self._update(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "def load_glove(word_index):\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    embeddings_index = dict(get_coefs(*o.split(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    unknown_words = []\n",
    "    \n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(word_index), embed_size))\n",
    "        \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "            if embedding_vector is None:\n",
    "                unknown_words.append((word, i))\n",
    "            else:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('\\nTotal unknowns glove', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "def load_wiki(word_index):\n",
    "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    embeddings_index = dict(get_coefs(*o.split(' ')) for o in open(EMBEDDING_FILE) if len(o) > 100)\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    unknown_words = []\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(word_index), embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "            if embedding_vector is None:\n",
    "                unknown_words.append((word, i))\n",
    "            else:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('\\nTotal unknowns wiki', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "def load_parag(word_index):\n",
    "    def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "    embeddings_index = dict(get_coefs(*o.split(' '))\n",
    "                            for o in open(EMBEDDING_FILE, encoding='utf8', errors='ignore')\n",
    "                            if len(o) > 100)\n",
    "\n",
    "    all_embs = np.stack(list(embeddings_index.values()))\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    unknown_words = []\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (len(word_index), embed_size))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is None:\n",
    "            embedding_vector = embeddings_index.get(word.lower())\n",
    "            if embedding_vector is None:\n",
    "                unknown_words.append((word, i))\n",
    "            else:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('\\nTotal unknowns parag', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words\n",
    "\n",
    "\n",
    "# https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "def load_ggle(word_index):\n",
    "    EMBEDDING_FILE = f'{mydir}/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "    embeddings_index = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "    embed_size = embeddings_index.get_vector('known').size\n",
    "\n",
    "    unknown_words = []\n",
    "    embedding_matrix = (np.random.rand(len(word_index), embed_size) - 0.5) / 5.0\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[i] = embeddings_index.get_vector(word)\n",
    "        else:\n",
    "            word_lower = word.lower()\n",
    "            if word_lower in embeddings_index:\n",
    "                embedding_matrix[i] = embeddings_index.get_vector(word_lower)\n",
    "            else:\n",
    "                unknown_words.append((word, i))\n",
    "\n",
    "    print('\\nTotal unknowns ggle', len(unknown_words))\n",
    "    print(unknown_words[-10:])\n",
    "\n",
    "    del embeddings_index\n",
    "    gc.collect()\n",
    "    return embedding_matrix, unknown_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, h_size, n_layers, dropout, padding_idx, \n",
    "                 pretrained_embedding=None, fix_embedding=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.is_pretrained = pretrained_embedding is not None\n",
    "        \n",
    "        if self.is_pretrained:\n",
    "            self.embed = nn.Embedding.from_pretrained(pretrained_embedding, freeze=fix_embedding)\n",
    "            self.embed.padding_idx = padding_idx\n",
    "        else:\n",
    "            self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=padding_idx)\n",
    "            \n",
    "        self.embed_drop = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(embed_dim, h_size, n_layers, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(2*n_layers*h_size, h_size),\n",
    "            nn.BatchNorm1d(h_size),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(h_size, 1),\n",
    "        )\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        if not self.is_pretrained:\n",
    "            d = self.embed.weight.size(1)\n",
    "            nn.init.uniform_(self.embed.weight, -1/np.sqrt(d), 1/np.sqrt(d))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.embed_drop(x)\n",
    "        x, _ = self.gru(x)\n",
    "        x, _ = torch.max(x, 1)\n",
    "        x = self.out(x).squeeze(1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameDataset(data.Dataset):\n",
    "     \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "     def __init__(self, examples, fields, filter_pred=None):\n",
    "         \"\"\"\n",
    "         Create a dataset from a pandas dataframe of examples and Fields\n",
    "         Arguments:\n",
    "             examples pd.DataFrame: DataFrame of examples\n",
    "             fields {str: Field}: The Fields to use in this tuple. The\n",
    "                 string is a field name, and the Field is the associated field.\n",
    "             filter_pred (callable or None): use only exanples for which\n",
    "                 filter_pred(example) is true, or use all examples if None.\n",
    "                 Default is None\n",
    "         \"\"\"\n",
    "         self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "         if filter_pred is not None:\n",
    "             self.examples = filter(filter_pred, self.examples)\n",
    "         self.fields = dict(fields)\n",
    "         # Unpack field tuples\n",
    "         for n, f in list(self.fields.items()):\n",
    "             if isinstance(n, tuple):\n",
    "                 self.fields.update(zip(n, f))\n",
    "                 del self.fields[n]\n",
    "                    \n",
    "class SeriesExample(data.Example):\n",
    "     \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "     @classmethod\n",
    "     def fromSeries(cls, data, fields):\n",
    "         return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "     @classmethod\n",
    "     def fromdict(cls, data, fields):\n",
    "         ex = cls()\n",
    "\n",
    "         for key, field in fields.items():\n",
    "             if key not in data:\n",
    "                 raise ValueError(\"Specified key {} was not found in \"\n",
    "                 \"the input data\".format(key))\n",
    "             if field is not None:\n",
    "                 setattr(ex, key, field.preprocess(data[key]))\n",
    "             else:\n",
    "                 setattr(ex, key, data[key])\n",
    "         return ex\n",
    "\n",
    "# Simple wrapper to join torchtext and catalyst API\n",
    "\n",
    "class IteratorWrapper(torch.utils.data.DataLoader):\n",
    "    __initialized__ = False\n",
    "\n",
    "    def __init__(self, iter: iter):\n",
    "        self.batch_size = iter.batch_size\n",
    "        self.num_workers = 1\n",
    "        self.collate_fn = None\n",
    "        self.pin_memory = False\n",
    "        self.drop_last = False\n",
    "        self.timeout = 0\n",
    "        self.worker_init_fn = None\n",
    "        self.sampler = iter\n",
    "        self.batch_sampler = iter\n",
    "        self.__initialized__ = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        return map(lambda batch: {\n",
    "                    'features': batch.text,\n",
    "                    'targets': batch.target,\n",
    "                }, self.batch_sampler.__iter__())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "puncts = ',.\":)(-!?|;\\'$&/[]>%=#*+\\\\•~@£·_{}©^®`<→°€™›♥←×§″′Â█½à…“★”–●â►−¢²¬░¶↑±¿▾═¦║\\\n",
    "―¥▓—‹─▒：¼⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸¾Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡√'\n",
    "\n",
    "\n",
    "def clean_text(x, puncts=puncts): #добавляет пробелы вокруг пунктуации\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_numbers(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497e68d141e0461fa566e55b21fb85d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f8914c64624e4783d70d5ed7563805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3469c30db18449adb9c3e629acc8ac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1306122.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69f9f6fbf8b4f26a559a0209bcc3d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=914280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd582a76775c4eb3afe3199cb6275829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=914280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e438e9679943ea8144c1a86a794008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=914280.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{mydir}/train.csv', index_col=0)\n",
    "df_train = df_train.rename(columns={'question_text': 'text'})\n",
    "\n",
    "df_train['text'] = df_train['text'].progress_apply(str.lower)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_text)\n",
    "df_train['text'] = df_train['text'].progress_apply(clean_numbers)\n",
    "\n",
    "df_train, df_test = train_test_split(df_train, train_size=0.7, random_state=SEED)\n",
    "\n",
    "augmented = pd.read_csv(f'{mydir}/augmented_fairseq.csv', index_col=0)\n",
    "augmented = augmented.rename(columns={'question_text': 'text'})\n",
    "augmented['text'] = augmented['text'].str[2:-2]\n",
    "\n",
    "augmented['text'] = augmented['text'].progress_apply(str.lower)\n",
    "augmented['text'] = augmented['text'].progress_apply(clean_text)\n",
    "augmented['text'] = augmented['text'].progress_apply(clean_numbers)\n",
    "\n",
    "df_train = pd.concat([df_train, augmented]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1645708, 182857)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 50\n",
    "\n",
    "TEXT = data.Field(\n",
    "                  postprocessing = lambda batch, vocab: [x[:max_len] for x in batch],\n",
    "                  lower=True,\n",
    "                  tokenize='spacy', \n",
    "                  tokenizer_language='en', \n",
    "                  batch_first=True)\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "\n",
    "train = DataFrameDataset(df_train, fields={'text': TEXT, 'target': LABEL})\n",
    "test = DataFrameDataset(df_test, fields={'text': TEXT, 'target': LABEL})\n",
    "\n",
    "TEXT.build_vocab(train, test, min_freq=1)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "train, valid = train.split(split_ratio=0.9)\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195394"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unknowns glove 74234\n",
      "[('할', 195382), ('했다', 195383), ('행복하게', 195384), ('혀', 195385), ('호', 195386), ('흡', 195387), ('\\uf0d8what', 195388), ('\\ufeffwhat', 195389), ('ｈow', 195392), ('ｘ', 195393)]\n",
      "\n",
      "Total unknowns wiki 102249\n",
      "[('했다', 195383), ('행복하게', 195384), ('혀', 195385), ('호', 195386), ('흡', 195387), ('\\uf0d8what', 195388), ('\\ufeffwhat', 195389), ('＄', 195390), ('ｈow', 195392), ('ｘ', 195393)]\n",
      "\n",
      "Total unknowns parag 53170\n",
      "[('할', 195382), ('했다', 195383), ('행복하게', 195384), ('혀', 195385), ('호', 195386), ('흡', 195387), ('\\uf0d8what', 195388), ('\\ufeffwhat', 195389), ('ｈow', 195392), ('ｘ', 195393)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:28:48.087625 140359865444160 utils_any2vec.py:341] loading projection weights from /data2/competitions/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n",
      "I0302 18:29:34.826177 140359865444160 utils_any2vec.py:405] loaded (3000000, 300) matrix from /data2/competitions/quora-insincere-questions-classification/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unknowns ggle 116591\n",
      "[('행복하게', 195384), ('혀', 195385), ('호', 195386), ('흡', 195387), ('\\uf0d8what', 195388), ('\\ufeffwhat', 195389), ('＄', 195390), ('＞', 195391), ('ｈow', 195392), ('ｘ', 195393)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/data2/competitions/quora-insincere-questions-classification/embedding_matrix_dup']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = dict(TEXT.vocab.stoi)\n",
    "embedding_matrix_1, _ = load_glove(word_index)\n",
    "embedding_matrix_2, _ = load_wiki(word_index)\n",
    "embedding_matrix_3, _ = load_parag(word_index)\n",
    "embedding_matrix_4, _ = load_ggle(word_index)\n",
    "\n",
    "embedding_matrix = np.hstack((embedding_matrix_1, \n",
    "                              embedding_matrix_2,\n",
    "                              embedding_matrix_3,\n",
    "                              embedding_matrix_4))\n",
    "del embedding_matrix_1, embedding_matrix_2, embedding_matrix_3, embedding_matrix_4\n",
    "\n",
    "joblib.dump(embedding_matrix, f'{mydir}/embedding_matrix_dup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = joblib.load(f'{mydir}/embedding_matrix_dup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/denis.litvinov/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "h_size = 128\n",
    "num_epochs = 10 \n",
    "n_layers = 1\n",
    "dropout = 0.1\n",
    "embed_dim = embedding_matrix.shape[1]\n",
    "batch_size = 512\n",
    "\n",
    "\n",
    "train_iter, valid_iter, test_iter = data.BucketIterator.splits((train, valid, test), \n",
    "                                                               batch_size=batch_size, \n",
    "                                                               sort_key=lambda x: len(x.text),\n",
    "                                                               sort=True,\n",
    "                                                               device=DEVICE)\n",
    "train_iter = IteratorWrapper(train_iter)\n",
    "valid_iter = IteratorWrapper(valid_iter)\n",
    "test_iter = IteratorWrapper(test_iter)\n",
    "loaders = {'train': train_iter, 'valid': valid_iter}\n",
    "\n",
    "\n",
    "model = GRUModel(vocab_size=vocab_size, \n",
    "                 embed_dim=embed_dim, \n",
    "                 h_size=h_size, \n",
    "                 n_layers=n_layers, \n",
    "                 dropout=dropout, \n",
    "                 padding_idx=TEXT.vocab.stoi['<pad>'], \n",
    "                 pretrained_embedding=torch.tensor(embedding_matrix).float(), \n",
    "                 fix_embedding=True)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=2, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = f'{mydir}/log_quora1_dup'\n",
    "!rm -rf {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/denaas/text-augmentation\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/denaas/text-augmentation/runs/bjdzzb6a\" target=\"_blank\">https://app.wandb.ai/denaas/text-augmentation/runs/bjdzzb6a</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:29:43.742481 140359865444160 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:29:43.743592 140359865444160 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:29:44.008087 140359865444160 run_manager.py:951] resuming run from id: UnVuOnYxOmJqZHp6YjZhOnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:29:44.027082 140359865444160 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:29:44.320137 140352964880128 run_manager.py:1048] saving patches\n",
      "I0302 18:29:44.371698 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/config.yaml\n",
      "I0302 18:29:45.041044 140352964880128 run_manager.py:1052] saving pip packages\n",
      "I0302 18:29:45.042504 140352964880128 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:29:45.043643 140352964880128 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "wandb: WARNING Path /data2/competitions/quora-insincere-questions-classification/log_quora1_dup/wandb/ wasn't writable, using system temp directory\n",
      "I0302 18:29:45.350311 140352999483136 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:29:45.351584 140352999483136 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:29:45.352303 140352999483136 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:29:45.353474 140352999483136 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:29:45.371117 140352999483136 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/diff.patch\n",
      "I0302 18:29:45.372286 140352999483136 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/requirements.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  51% 1631/3215 [00:13<00:12, 129.34it/s, loss=0.059]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:00.632044 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train):  94% 3018/3215 [00:26<00:02, 82.47it/s, loss=0.166] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:13.648898 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 3205/3215 [00:29<00:00, 49.03it/s, loss=0.244]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:16.656267 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 3215/3215 [00:29<00:00, 107.98it/s, loss=0.353]\n",
      "1/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 158.53it/s, loss=0.314]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:19.708699 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:30:19.710001 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:30:22,139] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=123572.9128 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.1126\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=126760.2132 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:22.139730 140359865444160 logging.py:153] \n",
      "1/10 * Epoch 1 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=123572.9128 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.1126\n",
      "1/10 * Epoch 1 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=126760.2132 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  36% 1152/3215 [00:10<00:16, 121.56it/s, loss=0.048]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:32.413002 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  77% 2474/3215 [00:22<00:08, 91.82it/s, loss=0.094] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:44.418489 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train):  88% 2820/3215 [00:26<00:04, 85.28it/s, loss=0.153]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:30:48.425047 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/10 * Epoch (train): 100% 3215/3215 [00:32<00:00, 99.17it/s, loss=0.210]\n",
      "2/10 * Epoch (valid): 100% 358/358 [00:07<00:00, 48.22it/s, loss=0.237] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:31:02.786560 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:31:02.787737 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:31:09.791024 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:31:19.795473 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:31:25.799352 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:31:35,077] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=113461.0343 | _timers/batch_time=0.0053 | _timers/data_time=0.0041 | _timers/model_time=0.0011 | loss=0.0982\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119237.6418 | _timers/batch_time=0.0189 | _timers/data_time=0.0179 | _timers/model_time=0.0010 | loss=0.1142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:31:35.077609 140359865444160 logging.py:153] \n",
      "2/10 * Epoch 2 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=113461.0343 | _timers/batch_time=0.0053 | _timers/data_time=0.0041 | _timers/model_time=0.0011 | loss=0.0982\n",
      "2/10 * Epoch 2 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=119237.6418 | _timers/batch_time=0.0189 | _timers/data_time=0.0179 | _timers/model_time=0.0010 | loss=0.1142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  19% 625/3215 [00:05<00:19, 130.49it/s, loss=0.073]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:31:40.894947 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  58% 1879/3215 [00:15<00:11, 120.47it/s, loss=0.055]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:31:50.909386 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train):  79% 2538/3215 [00:21<00:06, 104.32it/s, loss=0.138]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:31:56.921505 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 * Epoch (train): 100% 3215/3215 [00:30<00:00, 104.73it/s, loss=0.130]\n",
      "3/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 158.78it/s, loss=0.270]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:32:08.943109 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:32:08.943978 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:32:12.945218 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:32:21.954688 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:32:28.959042 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:32:36,919] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118075.0616 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0911\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=125208.4177 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0010 | loss=0.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:32:36.919386 140359865444160 logging.py:153] \n",
      "3/10 * Epoch 3 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=118075.0616 | _timers/batch_time=0.0050 | _timers/data_time=0.0039 | _timers/model_time=0.0011 | loss=0.0911\n",
      "3/10 * Epoch 3 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=125208.4177 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0010 | loss=0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  31% 995/3215 [00:08<00:17, 129.27it/s, loss=0.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:32:45.016277 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  61% 1947/3215 [00:16<00:11, 110.97it/s, loss=0.065]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:32:53.025110 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train):  87% 2789/3215 [00:24<00:04, 95.21it/s, loss=0.140] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:33:01.045060 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/10 * Epoch (train): 100% 3215/3215 [00:30<00:00, 106.92it/s, loss=0.107]\n",
      "4/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 167.60it/s, loss=0.236]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:33:10.130794 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:33:10.131500 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:33:17.134274 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:33:23.137892 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:33:33.143790 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:33:38,327] \n",
      "4/10 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=121530.4187 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0847\n",
      "4/10 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=134389.2059 | _timers/batch_time=0.0044 | _timers/data_time=0.0035 | _timers/model_time=0.0009 | loss=0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:33:38.327310 140359865444160 logging.py:153] \n",
      "4/10 * Epoch 4 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=121530.4187 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0847\n",
      "4/10 * Epoch 4 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=134389.2059 | _timers/batch_time=0.0044 | _timers/data_time=0.0035 | _timers/model_time=0.0009 | loss=0.1099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  42% 1344/3215 [00:10<00:14, 129.12it/s, loss=0.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:33:49.245618 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  60% 1940/3215 [00:15<00:11, 107.30it/s, loss=0.094]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:33:54.251821 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train):  94% 3031/3215 [00:26<00:02, 80.37it/s, loss=0.188] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:34:05.265293 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/10 * Epoch (train): 100% 3215/3215 [00:29<00:00, 107.37it/s, loss=0.067]\n",
      "5/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 156.88it/s, loss=0.271]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:34:11.279843 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:34:11.280933 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:34:22.585362 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:34:25.586606 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:34:25,760] \n",
      "5/10 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=122039.9658 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0790\n",
      "5/10 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=128173.4590 | _timers/batch_time=0.0047 | _timers/data_time=0.0038 | _timers/model_time=0.0009 | loss=0.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:34:25.760475 140359865444160 logging.py:153] \n",
      "5/10 * Epoch 5 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=122039.9658 | _timers/batch_time=0.0049 | _timers/data_time=0.0038 | _timers/model_time=0.0011 | loss=0.0790\n",
      "5/10 * Epoch 5 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=128173.4590 | _timers/batch_time=0.0047 | _timers/data_time=0.0038 | _timers/model_time=0.0009 | loss=0.1140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 * Epoch (train):  42% 1353/3215 [00:11<00:14, 124.45it/s, loss=0.048]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:34:42.360959 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 * Epoch (train):  94% 3035/3215 [00:33<00:02, 70.73it/s, loss=0.148] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:34:59.380938 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 * Epoch (train):  96% 3098/3215 [00:34<00:01, 62.56it/s, loss=0.133]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:00.385976 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/10 * Epoch (train): 100% 3215/3215 [00:37<00:00, 86.76it/s, loss=0.065]\n",
      "6/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 153.05it/s, loss=0.294]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:05.633958 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:35:05.634685 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:35:15.955268 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-02 18:35:20,083] \n",
      "6/10 * Epoch 6 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=115520.0736 | _timers/batch_time=0.0068 | _timers/data_time=0.0057 | _timers/model_time=0.0011 | loss=0.0742\n",
      "6/10 * Epoch 6 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=122178.5187 | _timers/batch_time=0.0048 | _timers/data_time=0.0039 | _timers/model_time=0.0009 | loss=0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:20.083850 140359865444160 logging.py:153] \n",
      "6/10 * Epoch 6 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=115520.0736 | _timers/batch_time=0.0068 | _timers/data_time=0.0057 | _timers/model_time=0.0011 | loss=0.0742\n",
      "6/10 * Epoch 6 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=122178.5187 | _timers/batch_time=0.0048 | _timers/data_time=0.0039 | _timers/model_time=0.0009 | loss=0.1105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 * Epoch (train):  40% 1282/3215 [00:11<00:15, 122.04it/s, loss=0.024]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:31.167263 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 * Epoch (train):  44% 1406/3215 [00:12<00:14, 124.59it/s, loss=0.061]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:32.170906 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 * Epoch (train):  92% 2959/3215 [00:27<00:03, 78.96it/s, loss=0.122] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:47.190322 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/10 * Epoch (train): 100% 3215/3215 [00:31<00:00, 102.31it/s, loss=0.054]\n",
      "7/10 * Epoch (valid): 100% 358/358 [00:02<00:00, 158.33it/s, loss=0.284]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:35:54.230973 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:35:54.231799 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:36:03.236207 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:36:03.244806 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stop at 6 epoch\n",
      "[2020-03-02 18:36:08,848] \n",
      "7/10 * Epoch 7 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=116627.4067 | _timers/batch_time=0.0051 | _timers/data_time=0.0040 | _timers/model_time=0.0011 | loss=0.0700\n",
      "7/10 * Epoch 7 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=126607.9177 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:36:08.848874 140359865444160 logging.py:153] \n",
      "7/10 * Epoch 7 (train): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=116627.4067 | _timers/batch_time=0.0051 | _timers/data_time=0.0040 | _timers/model_time=0.0011 | loss=0.0700\n",
      "7/10 * Epoch 7 (valid): _base/lr=0.0010 | _base/momentum=0.9000 | _timers/_fps=126607.9177 | _timers/batch_time=0.0047 | _timers/data_time=0.0037 | _timers/model_time=0.0009 | loss=0.1157\n",
      "I0302 18:36:08.852340 140359865444160 run_manager.py:1068] shutting down system stats and metadata service\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top best models:\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora1_dup/checkpoints/train.4.pth\t0.1099\n",
      "/data2/competitions/quora-insincere-questions-classification/log_quora1_dup/checkpoints/train.6.pth\t0.1105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:36:09.238575 140359865444160 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:36:09.242645 140352999483136 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:36:09.246645 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:36:09.248886 140359865444160 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/log.txt\n",
      "I0302 18:36:09.251935 140359865444160 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/valid_log/events.out.tfevents.1583163016.UNIT-1482.9632.1\n",
      "I0302 18:36:09.252740 140359865444160 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/train_log/events.out.tfevents.1583162987.UNIT-1482.9632.0\n",
      "I0302 18:36:09.253377 140359865444160 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/train_log\n",
      "I0302 18:36:09.254012 140359865444160 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/checkpoints\n",
      "I0302 18:36:09.254483 140359865444160 run_manager.py:677] file/dir created: /tmp/wandb/run-20200302_152942-bjdzzb6a/valid_log\n"
     ]
    }
   ],
   "source": [
    "# use SupervisedWandbRunner runner to send statistics to wandb\n",
    "runner = dl.SupervisedWandbRunner(DEVICE)\n",
    "runner.train(model, \n",
    "             loaders=loaders,\n",
    "             num_epochs=num_epochs,\n",
    "             logdir=logdir,\n",
    "             criterion=nn.BCEWithLogitsLoss(),\n",
    "             optimizer=optimizer, \n",
    "             scheduler=scheduler,  \n",
    "             callbacks=[\n",
    "                dl.callbacks.CheckpointCallback(2), # save 2 best models (by epoch) into logdir\n",
    "                dl.callbacks.EarlyStoppingCallback(3), # stop training, if valid loss does not improve last 3 epochs\n",
    "             ],\n",
    "             # send current hyperparam values to wandb\n",
    "             monitoring_params={\n",
    "                 'entity': 'denaas', # your wandb username\n",
    "                 'project': 'text-augmentation', # project name\n",
    "                 'name': 'quora-embed-dup', # name of the specific run\n",
    "                 'group': 'examples',\n",
    "                 'config': {\n",
    "                     'model': 'bigru',\n",
    "                     'optimizer': str(optimizer),\n",
    "                     'scheduler': 'plateau',\n",
    "                     'early_stop': 3,\n",
    "                     'vocab_size': vocab_size,\n",
    "                     'h_size': h_size,\n",
    "                     'n_layers': n_layers,\n",
    "                     'dropout': dropout,\n",
    "                     'batch_size': batch_size,\n",
    "                     'embed_dim': embed_dim,\n",
    "                     'max_len': max_len,\n",
    "                 },\n",
    "             },\n",
    "#              check=True, # set if you want to check pipeline for correctness, without actual training\n",
    "             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.utils.unpack_checkpoint(dl.utils.load_checkpoint(f'{logdir}/checkpoints/best_full.pth'), model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905000556854883 0.31874999999999987 0.9697459995230024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0302 18:36:26.615827 140359865444160 run_manager.py:924] system metrics and metadata threads started\n",
      "I0302 18:36:26.616446 140359865444160 run_manager.py:933] checking resume status, waiting at most 10 seconds\n",
      "I0302 18:36:27.233987 140352956487424 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:36:27.633795 140359865444160 run_manager.py:951] resuming run from id: UnVuOnYxOmJqZHp6YjZhOnRleHQtYXVnbWVudGF0aW9uOmRlbmFhcw==\n",
      "I0302 18:36:27.669797 140359865444160 run_manager.py:963] upserting run before process can begin, waiting at most 10 seconds\n",
      "I0302 18:36:27.936141 140352899876608 run_manager.py:1048] saving patches\n",
      "I0302 18:36:28.545298 140352899876608 run_manager.py:1052] saving pip packages\n",
      "I0302 18:36:28.547137 140352899876608 run_manager.py:1054] initializing streaming files api\n",
      "I0302 18:36:28.548027 140352899876608 run_manager.py:1061] unblocking file change observer, beginning sync with W&B servers\n",
      "I0302 18:36:28.549411 140352956487424 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/config.yaml\n",
      "I0302 18:36:28.561147 140359865444160 run_manager.py:1068] shutting down system stats and metadata service\n",
      "I0302 18:36:28.618419 140359865444160 run_manager.py:1080] stopping streaming files and file change observer\n",
      "I0302 18:36:28.817950 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:36:28.820315 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:36:28.822816 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n",
      "I0302 18:36:28.828741 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-events.jsonl\n",
      "I0302 18:36:28.832799 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/requirements.txt\n",
      "I0302 18:36:28.837031 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-metadata.json\n",
      "I0302 18:36:28.840299 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/diff.patch\n",
      "I0302 18:36:28.845162 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-history.jsonl\n",
      "I0302 18:36:28.849176 140359865444160 run_manager.py:688] file/dir modified: /tmp/wandb/run-20200302_152942-bjdzzb6a/wandb-summary.json\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "\n",
    "# find threshold\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, valid_iter)\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in valid_iter])\n",
    "res = scipy.optimize.minimize(\n",
    "    lambda t: -metrics.f1_score(y_true, (y_proba >= t).astype(np.int)),\n",
    "    x0=0.5,\n",
    "    method='Nelder-Mead',\n",
    "    tol=1e-3,\n",
    ")\n",
    "threshold = res.x[0]\n",
    "\n",
    "\n",
    "runner = dl.SupervisedRunner()\n",
    "y_proba = runner.predict_loader(model, test_iter)\n",
    "y_proba = 1 / (1 + np.exp(-y_proba))\n",
    "y_true = np.concatenate([x['targets'].cpu().numpy() for x in test_iter])\n",
    "\n",
    "auc_test = metrics.roc_auc_score(y_true, y_proba)\n",
    "f1_test = metrics.f1_score(y_true, (y_proba >= threshold).astype(np.int))\n",
    "\n",
    "print(f1_test, threshold, auc_test)\n",
    "wandb.log({'scores/f1': f1_test, 'scores/f1_threshold': threshold, 'scores/f1_auc': auc_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
