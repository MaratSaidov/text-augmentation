{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "snlp-bilstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLyltlYH-frI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%env CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bchgg4iZ_5um",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WdIFqUXnPvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HWbKmUyykgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "def get_device(gpu_no):\n",
        "\tif torch.cuda.is_available():\n",
        "\t\ttorch.cuda.set_device(gpu_no)\n",
        "\t\treturn torch.device('cuda:{}'.format(gpu_no))\n",
        "\telse:\n",
        "\t\treturn torch.device('cpu')\n",
        "  \n",
        "def to_device(data, device):\n",
        "\tif isinstance(data, (list, tuple)):\n",
        "\t\treturn [to_device(x, device) for x in data]\n",
        "\treturn data.to(device, non_blocking=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJUg6ODp_PUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = get_device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JiRRQXGtZzkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Описание модели\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pdb\n",
        "from torch import cuda\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "\tdef __init__(self, options):\n",
        "\t\tsuper(BiLSTM, self).__init__()\n",
        "\t\tself.embedding = nn.Embedding(options['vocab_size'], options['embed_dim'])\n",
        "\t\tself.projection = nn.Linear(options['embed_dim'], 300)\n",
        "\t\tself.dropout = nn.Dropout(p = options['dp_ratio'])\n",
        "\t\tself.lstm = nn.LSTM(300, options['d_hidden'], 3)\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\t\tself.out = nn.Sequential(\n",
        "\t\t\tnn.Linear(1024, 1024),\n",
        "\t\t\tself.relu,\n",
        "\t\t\tself.dropout,\n",
        "\t\t\tnn.Linear(1024, 1024),\n",
        "\t\t\tself.relu,\n",
        "\t\t\tself.dropout,\n",
        "\t\t\tnn.Linear(1024, 1024),\n",
        "\t\t\tself.relu,\n",
        "\t\t\tself.dropout,\n",
        "\t\t\tnn.Linear(1024, options['out_dim'])\n",
        "\t\t)\n",
        "\t\tpass\n",
        "\n",
        "\tdef forward(self, batch):\n",
        "\t\tpremise_embed = self.embedding(batch.premise)\n",
        "\t\thypothesis_embed = self.embedding(batch.hypothesis)\n",
        "\t\tpremise_proj = self.relu(self.projection(premise_embed))\n",
        "\t\thypothesis_proj = self.relu(self.projection(hypothesis_embed))\n",
        "\t\tencoded_premise, _ = self.lstm(premise_proj)\n",
        "\t\tencoded_hypothesis, _ = self.lstm(hypothesis_proj)\n",
        "\t\tpremise = encoded_premise.sum(dim = 1)\n",
        "\t\thypothesis = encoded_hypothesis.sum(dim = 1)\n",
        "\t\tcombined = torch.cat((premise, hypothesis), 1)\n",
        "\t\treturn self.out(combined)\n",
        "\n",
        "def bilstm(options):\n",
        "\treturn BiLSTM(options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85bYnq1I7R2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "inputs = data.Field(lower=True, tokenize='spacy', batch_first=True)\n",
        "answers = data.Field(sequential=False, unk_token=None, is_target=True)\n",
        "\n",
        "train, dev, test = datasets.SNLI.splits(inputs, answers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VLRf8HHaZzk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "import dill\n",
        "import pdb\t\n",
        "\n",
        "\n",
        "class SNLI():\n",
        "\tdef __init__(self, options):\n",
        "\t\tself.inputs = inputs\n",
        "\t\tself.answers = answers\n",
        "\n",
        "\t\t# Считаем данные из JSON\n",
        "\t\tself.train, self.dev, self.test = train, dev, test\n",
        "\n",
        "\t\t# Построим входной и выходной словарь\n",
        "\t\tself.inputs.build_vocab(self.train, self.dev)\n",
        "\t\tself.answers.build_vocab(self.train)\n",
        "  \n",
        "\t\t# Разобьем выборку на train, test, dev\n",
        "\t\tself.train_iter, self.dev_iter, self.test_iter = data.Iterator.splits((self.train, self.dev, self.test), \n",
        "\t\t\t                     batch_size=options['batch_size'], \n",
        "\t\t\t\t\t\t\t\t device=device)\n",
        "\n",
        "\n",
        "\tdef vocab_size(self):\n",
        "\t\treturn len(self.inputs.vocab)\n",
        "\n",
        "\tdef out_dim(self):\n",
        "\t\treturn len(self.answers.vocab)\n",
        "\n",
        "\tdef labels(self):\n",
        "\t\treturn self.answers.vocab.stoi\n",
        "\n",
        "def snli(options):\n",
        "\treturn SNLI(options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E6HwFaZPZzlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "def training_params():\n",
        "\tparser = ArgumentParser(description='Параметры для обучения')\n",
        "\tparser.add_argument('--dataset', type=str, default='snli')\n",
        "\tparser.add_argument('--model', type=str, default='bilstm')\n",
        "\tparser.add_argument('--gpu', type=int, default=0)\n",
        "\tparser.add_argument('--batch_size', type=int, default=128)\n",
        "\tparser.add_argument('--embed_dim', type=int, default=300)\n",
        "\tparser.add_argument('--d_hidden', type=int, default=512)\n",
        "\tparser.add_argument('--dp_ratio', type=int, default=0.2)\n",
        "\tparser.add_argument('--epochs', type=int, default=50)\n",
        "\tparser.add_argument('--lr', type=float, default=.001)\n",
        "\tparser.add_argument('--combine', type=str, default='cat')\n",
        "\tparser.add_argument('--save_model', action='store_false', default=True)\n",
        "\targs = parser.parse_args()\n",
        "\treturn args\n",
        "\n",
        "def evaluate_params():\n",
        "\tparser = ArgumentParser(description='Подсчёт качества на валидационной выборке')\n",
        "\tparser.add_argument('--dataset', type=str, default='snli')\n",
        "\tparser.add_argument('--model', type=str, default='bilstm')\n",
        "\tparser.add_argument('--gpu', type=int, default=0)\n",
        "\tparser.add_argument('--batch_size', type=int, default=128)\n",
        "\tparser.add_argument('--save_path', type=str, default = \"save/bilstm-snli-model.pt\")\n",
        "\targs = parser.parse_args()\n",
        "\treturn args\n",
        "\n",
        "def get_args(mode):\n",
        "\tif mode == \"train\":\n",
        "\t\treturn training_params()\n",
        "\telif mode == \"evaluate\":\n",
        "\t\treturn evaluate_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk7kTg7T8ksP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_options = {'batch_size': 128, 'device': 0}\n",
        "dataset = snli(dataset_options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "buk-3rBXZzlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.optim as O\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import datetime\n",
        "import pdb\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import time\n",
        "\n",
        "class Train():\n",
        "    def __init__(self):\n",
        "        print(\"Началось выполнение обучения: {}\".format(datetime.datetime.now()))\n",
        "        self.args = get_args(\"train\")\n",
        "        self.device = device # args.gpu -- это номер используемого gpu\n",
        "\n",
        "        self.dataset_options = {\n",
        "                                'batch_size': self.args.batch_size, # по умолчанию равен 128\n",
        "                                'device': self.device\n",
        "                               }\n",
        "        self.dataset = dataset\n",
        "\n",
        "        self.model_options = { # Возьмем гиперпараметры, предложенные автором\n",
        "                                    'vocab_size': self.dataset.vocab_size(), #self.dataset.vocab_size(), \n",
        "                                    'embed_dim': 300, #self.args.embed_dim,\n",
        "                                    'out_dim': self.dataset.out_dim(),\n",
        "                                    'dp_ratio': 0.2, #self.args.dp_ratio,\n",
        "                                    'd_hidden': 512, #self.args.d_hidden\n",
        "                                }\n",
        "        self.model = bilstm(self.model_options)\n",
        "        self.model.to(device)\n",
        "        self.criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "        self.opt = O.Adam(self.model.parameters(), lr=self.args.lr)\n",
        "        self.best_accuracy = -1\n",
        "        print(\"resource preparation done: {}\".format(datetime.datetime.now()))\n",
        "\n",
        "    def save_model(self, current_accuracy):\n",
        "        if current_accuracy > self.best_accuracy:\n",
        "            self.best_accuracy = current_accuracy\n",
        "            torch.save({\n",
        "                'accuracy': self.best_accuracy,\n",
        "                'options': self.model_options,\n",
        "                'model_dict': self.model.state_dict(),\n",
        "            }, 'save/' + \"{}-{}-model.pt\".format(self.args.model, self.args.dataset))\n",
        "        pass\n",
        "\n",
        "    def train(self):\n",
        "        self.model.train()\n",
        "        self.dataset.train_iter.init_epoch()\n",
        "        n_correct, n_total, n_loss = 0, 0, 0\n",
        "        print(f\"Количество итераций: {len(self.dataset.train_iter)}\")\n",
        "        for batch_idx, batch in tqdm(enumerate(self.dataset.train_iter)):\n",
        "            self.opt.zero_grad()\n",
        "            answer = self.model(batch)\n",
        "            loss = self.criterion(answer, batch.label)\n",
        "\n",
        "            n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "            n_total += batch.batch_size\n",
        "            n_loss += loss.item()\n",
        "\n",
        "            loss.backward(); self.opt.step()\n",
        "        train_loss = n_loss / n_total\n",
        "        train_acc = 100. * n_correct / n_total\n",
        "        return train_loss, train_acc\n",
        "\n",
        "    def validate(self):\n",
        "        self.model.eval()\n",
        "        self.dataset.dev_iter.init_epoch()\n",
        "        n_correct, n_total, n_loss = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(self.dataset.dev_iter):\n",
        "                answer = self.model(batch)\n",
        "                loss = self.criterion(answer, batch.label)\n",
        "                n_correct += (torch.max(answer, 1)[1].view(batch.label.size()) == batch.label).sum().item()\n",
        "                n_total += batch.batch_size\n",
        "                n_loss += loss.item()\n",
        "\n",
        "            val_loss = n_loss / n_total\n",
        "            val_acc = 100. * n_correct / n_total\n",
        "            return val_loss, val_acc\n",
        "\n",
        "    def execute(self):\n",
        "        for epoch in range(self.args.epochs):\n",
        "            start = time.time()\n",
        "            train_loss, train_acc = self.train()\n",
        "            val_loss, val_acc = self.validate()\n",
        "            if self.args.save_model:\n",
        "                self.save_model(val_acc)\n",
        "            print(\"time taken: {}   epoch: {}   Training loss: {}   Training Accuracy: {}   Validation loss: {}   Validation Accuracy: {}\".format(\n",
        "                round(time.time()-start, 2), epoch, round(train_loss, 3), round(train_acc, 3), round(val_loss, 3), round(val_acc, 3)\n",
        "            ))\n",
        "\n",
        "sys.argv[1] = \"--dataset=snli\"\n",
        "sys.argv[2] = \"--model=bilstm\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcesaBLFOh8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task = Train()\n",
        "task.execute()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh8tx3eHOY6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss, val_acc = task.validate()\n",
        "if task.args.save_model:\n",
        "    task.save_model(val_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYGjQH4uRzlG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "88b3d747-43f4-4758-a04a-e29e4a9709ef"
      },
      "source": [
        "print(val_loss, val_acc)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7217575674787621 69.32534037797195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQzVF8x2R_hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save({'model_dict': task.model.state_dict()}, 'drive/My Drive/text-augmentation/github-baseline.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLP_kDbWS0CZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}